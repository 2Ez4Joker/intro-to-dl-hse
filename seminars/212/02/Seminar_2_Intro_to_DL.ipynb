{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Семинар 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## План ноутбука\n",
    "\n",
    "1. Высокоуровневое API для обучение нейросетей в `PyTorch`\n",
    "2. Обучение первой нейросети в `PyTorch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Высокоуровневое API для обучение нейросетей в `PyTorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Создание объекта нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "*args\n",
    "[]\n",
    "()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W x + b\n",
    "\n",
    "in_features -> out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Linear(700, 500),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(500, 200),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(200, 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=700, out_features=500, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=500, out_features=200, bias=True)\n",
       "  (3): ReLU()\n",
       "  (4): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=700, out_features=500, bias=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0046, -0.0833,  0.0331, -0.0429, -0.0125, -0.0082,  0.0663, -0.0318,\n",
       "         -0.0565,  0.0647]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(1, 700)\n",
    "\n",
    "net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "net = nn.Sequential(\n",
    "    OrderedDict(\n",
    "        [\n",
    "            ('linear1', nn.Linear(700, 500)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('linear2', nn.Linear(500, 200)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('linear3', nn.Linear(200, 10))\n",
    "        ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (linear1): Linear(in_features=700, out_features=500, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (linear2): Linear(in_features=500, out_features=200, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (linear3): Linear(in_features=200, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=700, out_features=500, bias=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 10])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = torch.rand(6, 700)\n",
    "\n",
    "net(input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# необходимо отнаследоваться от nn.Module и определить методы __init__ и forward\n",
    "\n",
    "class CustomTaskNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(700, 500)\n",
    "        self.linear2 = nn.Linear(500, 500)\n",
    "        self.linear3 = nn.Linear(500, 10)\n",
    "\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.activation(self.linear1(x))\n",
    "        output = self.activation(self.linear2(output))\n",
    "        output = self.activation(self.linear2(output))\n",
    "        output = self.linear3(output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "net = CustomTaskNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 10])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTaskNetwork(\n",
       "  (linear1): Linear(in_features=700, out_features=500, bias=True)\n",
       "  (linear3): Linear(in_features=500, out_features=10, bias=True)\n",
       "  (linear2): Linear(in_features=500, out_features=500, bias=True)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[10], line 14\u001b[0m, in \u001b[0;36mCustomTaskNetwork.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 14\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     15\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(output))\n\u001b[1;32m     16\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(output))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)"
     ]
    }
   ],
   "source": [
    "net(input_tensor).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 10])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(input_tensor.cuda()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTaskNetwork(\n",
       "  (linear1): Linear(in_features=700, out_features=500, bias=True)\n",
       "  (linear3): Linear(in_features=500, out_features=10, bias=True)\n",
       "  (linear2): Linear(in_features=500, out_features=500, bias=True)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTaskNetwork(\n",
       "  (linear1): Linear(in_features=700, out_features=500, bias=True)\n",
       "  (linear3): Linear(in_features=500, out_features=10, bias=True)\n",
       "  (linear2): Linear(in_features=500, out_features=500, bias=True)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomTaskNetwork(\n",
       "  (linear1): Linear(in_features=700, out_features=500, bias=True)\n",
       "  (linear3): Linear(in_features=500, out_features=10, bias=True)\n",
       "  (linear2): Linear(in_features=500, out_features=500, bias=True)\n",
       "  (activation): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0289,  0.0207, -0.0158,  ...,  0.0181,  0.0082,  0.0071],\n",
       "        [-0.0277,  0.0350,  0.0145,  ..., -0.0131,  0.0354, -0.0099],\n",
       "        [ 0.0182,  0.0227, -0.0094,  ...,  0.0338, -0.0040, -0.0336],\n",
       "        ...,\n",
       "        [ 0.0134, -0.0242,  0.0159,  ...,  0.0244,  0.0152, -0.0095],\n",
       "        [ 0.0265,  0.0196, -0.0347,  ..., -0.0337, -0.0344,  0.0017],\n",
       "        [ 0.0112, -0.0045,  0.0262,  ...,  0.0193, -0.0022,  0.0070]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.0289,  0.0207, -0.0158,  ...,  0.0181,  0.0082,  0.0071],\n",
       "         [-0.0277,  0.0350,  0.0145,  ..., -0.0131,  0.0354, -0.0099],\n",
       "         [ 0.0182,  0.0227, -0.0094,  ...,  0.0338, -0.0040, -0.0336],\n",
       "         ...,\n",
       "         [ 0.0134, -0.0242,  0.0159,  ...,  0.0244,  0.0152, -0.0095],\n",
       "         [ 0.0265,  0.0196, -0.0347,  ..., -0.0337, -0.0344,  0.0017],\n",
       "         [ 0.0112, -0.0045,  0.0262,  ...,  0.0193, -0.0022,  0.0070]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0241, -0.0367,  0.0284, -0.0128, -0.0097, -0.0328, -0.0102, -0.0323,\n",
       "          0.0149, -0.0077, -0.0029, -0.0067,  0.0203,  0.0337, -0.0155, -0.0093,\n",
       "         -0.0233,  0.0117,  0.0314, -0.0334,  0.0309,  0.0317,  0.0023,  0.0058,\n",
       "          0.0257,  0.0281, -0.0123,  0.0087,  0.0104,  0.0271, -0.0232,  0.0362,\n",
       "         -0.0047,  0.0171, -0.0191, -0.0034, -0.0196, -0.0101, -0.0352,  0.0341,\n",
       "          0.0002, -0.0091,  0.0343, -0.0256, -0.0141, -0.0351, -0.0359, -0.0288,\n",
       "         -0.0195, -0.0047,  0.0041,  0.0324,  0.0264, -0.0099,  0.0136,  0.0155,\n",
       "          0.0227, -0.0182, -0.0272, -0.0321, -0.0187, -0.0180, -0.0207,  0.0233,\n",
       "          0.0338,  0.0377,  0.0328,  0.0253, -0.0053,  0.0111, -0.0102,  0.0034,\n",
       "         -0.0282,  0.0208,  0.0228,  0.0120, -0.0226, -0.0207, -0.0271, -0.0240,\n",
       "          0.0135,  0.0186, -0.0122, -0.0080, -0.0304,  0.0248,  0.0096,  0.0179,\n",
       "         -0.0257, -0.0166, -0.0071, -0.0293, -0.0194,  0.0092,  0.0256, -0.0063,\n",
       "          0.0195,  0.0295, -0.0013,  0.0316, -0.0032,  0.0034,  0.0318, -0.0190,\n",
       "         -0.0281,  0.0373, -0.0172,  0.0325, -0.0081, -0.0012, -0.0032,  0.0195,\n",
       "          0.0182, -0.0141, -0.0060,  0.0099,  0.0374, -0.0094,  0.0126,  0.0026,\n",
       "          0.0001,  0.0150,  0.0270, -0.0369, -0.0238, -0.0113, -0.0098,  0.0221,\n",
       "         -0.0036,  0.0270,  0.0046,  0.0120, -0.0335, -0.0060,  0.0339,  0.0187,\n",
       "         -0.0084, -0.0135, -0.0119,  0.0181, -0.0306, -0.0328,  0.0278,  0.0026,\n",
       "          0.0139,  0.0258,  0.0043,  0.0078, -0.0066,  0.0068, -0.0257, -0.0069,\n",
       "         -0.0068, -0.0027,  0.0340, -0.0203,  0.0065, -0.0331,  0.0249, -0.0261,\n",
       "          0.0267, -0.0351,  0.0258, -0.0230,  0.0001, -0.0011,  0.0317,  0.0261,\n",
       "          0.0360, -0.0351, -0.0263, -0.0014,  0.0339,  0.0069,  0.0039,  0.0269,\n",
       "          0.0235, -0.0348, -0.0274,  0.0116,  0.0264,  0.0285, -0.0192, -0.0070,\n",
       "          0.0344,  0.0064,  0.0376,  0.0342, -0.0223, -0.0173,  0.0370,  0.0332,\n",
       "          0.0311,  0.0266, -0.0155, -0.0019,  0.0123, -0.0052, -0.0316, -0.0333,\n",
       "         -0.0137, -0.0163, -0.0106, -0.0287,  0.0051,  0.0260,  0.0077,  0.0342,\n",
       "         -0.0138,  0.0120,  0.0007,  0.0002, -0.0071, -0.0152,  0.0276,  0.0176,\n",
       "          0.0055, -0.0089,  0.0324, -0.0176, -0.0223,  0.0199, -0.0271, -0.0074,\n",
       "          0.0059, -0.0161, -0.0115,  0.0317, -0.0203, -0.0054,  0.0248, -0.0360,\n",
       "         -0.0080,  0.0365,  0.0231,  0.0172, -0.0232,  0.0242, -0.0279,  0.0303,\n",
       "         -0.0013, -0.0046, -0.0255,  0.0319, -0.0357, -0.0054,  0.0213,  0.0261,\n",
       "          0.0076,  0.0310, -0.0318,  0.0340,  0.0142, -0.0029, -0.0276, -0.0093,\n",
       "          0.0146,  0.0170,  0.0144,  0.0319,  0.0283, -0.0284,  0.0140,  0.0036,\n",
       "         -0.0361, -0.0294, -0.0210,  0.0268, -0.0094, -0.0281,  0.0368,  0.0127,\n",
       "         -0.0262, -0.0067,  0.0060,  0.0217,  0.0091, -0.0124,  0.0299,  0.0112,\n",
       "          0.0177, -0.0048,  0.0061, -0.0272,  0.0348, -0.0234,  0.0250,  0.0118,\n",
       "          0.0017, -0.0055,  0.0075, -0.0088,  0.0103, -0.0009,  0.0306, -0.0320,\n",
       "         -0.0064,  0.0032,  0.0043, -0.0303,  0.0208,  0.0071,  0.0069, -0.0089,\n",
       "          0.0172,  0.0023,  0.0317,  0.0189, -0.0303,  0.0211, -0.0333,  0.0274,\n",
       "          0.0011, -0.0326, -0.0295,  0.0364, -0.0220, -0.0002,  0.0117,  0.0292,\n",
       "         -0.0319, -0.0064, -0.0101, -0.0363, -0.0235, -0.0202,  0.0179, -0.0347,\n",
       "         -0.0151,  0.0128, -0.0008, -0.0223,  0.0201, -0.0181, -0.0196,  0.0289,\n",
       "         -0.0013, -0.0117, -0.0187,  0.0256, -0.0343,  0.0356, -0.0175, -0.0134,\n",
       "         -0.0197,  0.0011, -0.0100,  0.0149,  0.0064, -0.0287,  0.0266,  0.0253,\n",
       "         -0.0158,  0.0359,  0.0103,  0.0127, -0.0103,  0.0254,  0.0309,  0.0299,\n",
       "         -0.0278,  0.0177, -0.0326,  0.0190, -0.0024, -0.0214,  0.0360, -0.0069,\n",
       "         -0.0149, -0.0349, -0.0337,  0.0098, -0.0139, -0.0316, -0.0372,  0.0374,\n",
       "          0.0121,  0.0344,  0.0290, -0.0286,  0.0043, -0.0214,  0.0252, -0.0345,\n",
       "         -0.0073, -0.0373, -0.0185, -0.0041,  0.0369, -0.0112, -0.0350, -0.0168,\n",
       "         -0.0311, -0.0025, -0.0186,  0.0072,  0.0159, -0.0118, -0.0291, -0.0314,\n",
       "          0.0061,  0.0170, -0.0088, -0.0271, -0.0021, -0.0026, -0.0190,  0.0223,\n",
       "          0.0180, -0.0200,  0.0028,  0.0295,  0.0143, -0.0092,  0.0030,  0.0251,\n",
       "          0.0136, -0.0085, -0.0308, -0.0368, -0.0214,  0.0357,  0.0067,  0.0118,\n",
       "          0.0011,  0.0026, -0.0187,  0.0031,  0.0110, -0.0368, -0.0092,  0.0235,\n",
       "         -0.0277, -0.0280, -0.0267,  0.0170,  0.0156, -0.0130,  0.0101, -0.0270,\n",
       "          0.0352, -0.0134,  0.0003,  0.0205,  0.0353, -0.0054,  0.0064, -0.0177,\n",
       "          0.0329, -0.0187,  0.0276,  0.0259, -0.0133,  0.0184, -0.0274,  0.0194,\n",
       "          0.0153, -0.0091,  0.0142,  0.0218,  0.0289, -0.0178, -0.0199, -0.0016,\n",
       "          0.0152, -0.0311, -0.0106, -0.0068,  0.0222,  0.0187, -0.0180, -0.0010,\n",
       "         -0.0213,  0.0114,  0.0244,  0.0079, -0.0081,  0.0037,  0.0222, -0.0088,\n",
       "         -0.0300,  0.0004,  0.0151, -0.0360,  0.0142,  0.0343, -0.0093,  0.0347,\n",
       "         -0.0136,  0.0196, -0.0281,  0.0030, -0.0358, -0.0143,  0.0333,  0.0118,\n",
       "         -0.0147,  0.0187,  0.0354,  0.0249], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0437,  0.0364,  0.0447,  ...,  0.0210, -0.0191, -0.0271],\n",
       "         [ 0.0414, -0.0166,  0.0111,  ..., -0.0177,  0.0346,  0.0251],\n",
       "         [-0.0006, -0.0332,  0.0008,  ...,  0.0310,  0.0443,  0.0023],\n",
       "         ...,\n",
       "         [ 0.0190,  0.0203, -0.0332,  ..., -0.0438, -0.0135, -0.0221],\n",
       "         [ 0.0147, -0.0072, -0.0179,  ..., -0.0155,  0.0323,  0.0270],\n",
       "         [ 0.0099, -0.0302,  0.0004,  ..., -0.0411, -0.0010, -0.0119]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0427, -0.0232, -0.0083,  0.0196, -0.0318,  0.0348, -0.0412,  0.0164,\n",
       "         -0.0097, -0.0179], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0186, -0.0304, -0.0207,  ..., -0.0041,  0.0185, -0.0173],\n",
       "         [-0.0382, -0.0023, -0.0217,  ...,  0.0334, -0.0362,  0.0414],\n",
       "         [ 0.0324, -0.0240, -0.0083,  ..., -0.0389,  0.0143, -0.0124],\n",
       "         ...,\n",
       "         [-0.0128,  0.0168,  0.0289,  ..., -0.0051, -0.0138, -0.0401],\n",
       "         [ 0.0357,  0.0075, -0.0385,  ...,  0.0328, -0.0170,  0.0383],\n",
       "         [-0.0350,  0.0442,  0.0409,  ...,  0.0017, -0.0089, -0.0119]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-1.7099e-03,  2.1052e-02,  3.1905e-03,  9.6159e-03,  2.1035e-02,\n",
       "         -2.1277e-02,  1.2616e-02, -3.0824e-02,  2.7923e-02,  4.3028e-02,\n",
       "         -4.4171e-02,  3.9664e-02, -1.2370e-02, -2.1143e-02, -2.4324e-02,\n",
       "          3.2168e-02,  1.8225e-02,  9.4844e-03,  4.2564e-02, -3.3345e-02,\n",
       "          1.0905e-02,  3.9634e-02,  2.4935e-02, -1.3114e-02, -7.2429e-03,\n",
       "          1.9432e-02, -1.9760e-02, -2.1420e-02,  1.4277e-02, -4.3666e-02,\n",
       "          3.7850e-03, -2.8832e-02,  1.0270e-02,  7.7023e-03, -2.3948e-05,\n",
       "          1.9982e-02,  4.0204e-02, -2.5552e-02, -3.8806e-02,  2.3297e-02,\n",
       "          1.8551e-02, -3.5196e-02,  4.4553e-02, -4.4459e-03,  1.6922e-02,\n",
       "         -2.4501e-02, -2.4812e-02, -3.6928e-02, -1.7975e-02,  8.2489e-04,\n",
       "          4.0318e-02,  2.7931e-02, -2.1893e-03, -1.7749e-02,  1.7442e-02,\n",
       "         -1.0218e-02,  2.7889e-04, -1.5717e-02,  2.2628e-02, -2.7281e-03,\n",
       "         -4.0731e-02,  2.0459e-02,  7.2801e-04, -3.7180e-02,  1.2595e-02,\n",
       "          2.3330e-02, -2.6614e-02,  2.7255e-02, -3.7461e-02,  4.0688e-02,\n",
       "         -1.3176e-02,  1.6109e-02, -9.1315e-03,  5.4194e-03,  6.9129e-03,\n",
       "         -5.3092e-03, -4.3527e-02,  2.2829e-02,  7.7954e-04,  3.3675e-02,\n",
       "          1.0872e-02,  2.2892e-02, -3.4833e-02, -7.7667e-03, -1.6867e-02,\n",
       "          4.6024e-03, -4.2890e-02, -2.0887e-02,  1.9243e-02,  3.5871e-02,\n",
       "          1.3244e-02, -2.6405e-02,  1.9951e-02,  1.4831e-02,  3.1961e-02,\n",
       "         -6.1723e-03,  2.1000e-02,  2.8997e-02, -3.8450e-02,  3.5310e-03,\n",
       "          4.4518e-02, -2.3697e-02,  1.1044e-02, -7.7797e-03,  1.5449e-02,\n",
       "          3.9487e-02, -4.4446e-02,  3.6269e-02,  1.5969e-02, -9.1293e-03,\n",
       "          1.3271e-02, -2.5626e-02,  3.6445e-02, -3.2636e-03,  1.0259e-02,\n",
       "          2.7223e-02, -3.6353e-02,  9.4154e-03, -2.2741e-02,  4.3404e-02,\n",
       "         -3.4709e-02, -1.2919e-02, -3.5713e-02,  2.1364e-02, -1.9060e-03,\n",
       "         -1.1253e-02, -2.5161e-02,  3.0309e-02,  9.2230e-05,  1.0513e-02,\n",
       "         -3.6416e-02,  8.5248e-03, -2.9330e-02,  1.3905e-02, -1.0323e-02,\n",
       "          1.1527e-02, -4.3624e-02, -1.3992e-02, -4.6646e-03,  1.0019e-02,\n",
       "         -1.1894e-02,  1.0935e-02, -4.1484e-02,  2.9089e-02,  1.9597e-02,\n",
       "          3.1194e-02,  1.9316e-02, -4.3188e-02, -3.2368e-02,  9.0949e-04,\n",
       "          3.5931e-02,  2.8776e-02, -4.1996e-02,  3.5485e-02,  1.1613e-04,\n",
       "         -6.1483e-03,  3.6123e-03,  6.7525e-03,  3.1756e-02, -4.1268e-02,\n",
       "         -3.4749e-02, -1.1682e-02,  1.3065e-02,  3.4541e-02, -3.9750e-02,\n",
       "          1.3085e-02,  1.7107e-04,  7.0596e-03, -1.5638e-02,  3.8069e-02,\n",
       "          3.2486e-03,  2.9219e-02,  3.9740e-02,  2.8430e-02,  7.4506e-03,\n",
       "         -6.6614e-03, -3.0603e-02,  1.2114e-02, -1.0091e-02, -7.5613e-04,\n",
       "          3.4938e-02, -3.3526e-03, -4.6702e-03, -3.7593e-02, -1.6819e-02,\n",
       "         -1.3045e-03, -2.7303e-03, -1.8369e-02, -1.3325e-02,  6.7699e-03,\n",
       "         -3.9553e-02,  1.7264e-02, -1.8990e-02,  2.2401e-02,  5.4209e-03,\n",
       "          1.2127e-02, -2.7636e-02,  1.4569e-02,  1.0620e-02, -5.2207e-03,\n",
       "          3.8062e-02,  2.0032e-02, -5.3433e-03, -1.1164e-02, -3.5192e-02,\n",
       "          3.8284e-02,  1.2538e-02, -2.2300e-02,  4.1490e-03, -1.7349e-02,\n",
       "         -1.5826e-02,  5.9756e-03,  2.8643e-02,  1.4909e-02, -2.6151e-02,\n",
       "          3.0213e-02,  2.3574e-02,  8.4391e-03, -2.3906e-02, -4.7402e-03,\n",
       "         -4.4011e-02, -1.9569e-02, -3.7633e-02, -4.3908e-02, -4.2854e-02,\n",
       "          1.6734e-02, -2.9000e-02,  2.6444e-02, -3.5762e-02, -8.8302e-03,\n",
       "         -1.0815e-02, -5.6124e-03, -8.4059e-03, -3.4946e-03,  2.9838e-02,\n",
       "          1.5598e-03,  3.2988e-02, -6.3099e-03, -2.2818e-02,  1.4727e-03,\n",
       "         -1.3798e-02,  1.0278e-02, -4.3593e-02,  2.0276e-02, -3.5138e-02,\n",
       "         -1.1949e-02,  1.5883e-02,  3.5919e-02, -3.7085e-03, -3.7121e-02,\n",
       "         -4.3184e-02,  3.3894e-02,  2.7983e-02,  2.1476e-02,  1.5536e-03,\n",
       "         -1.9854e-02,  2.7252e-02, -3.1548e-03,  3.7671e-02, -3.3659e-02,\n",
       "         -2.6127e-02,  6.7954e-03, -1.1486e-02, -2.0796e-02, -2.8710e-02,\n",
       "         -1.8864e-02, -7.4169e-03, -5.7270e-03,  4.2847e-02, -2.9568e-02,\n",
       "         -1.6526e-02, -1.9685e-02,  4.2677e-02, -4.7691e-04, -3.1012e-02,\n",
       "         -1.6628e-02, -1.8322e-02,  2.3220e-02,  8.4451e-03,  3.7875e-02,\n",
       "          2.0523e-02, -2.7545e-02, -4.2705e-02, -3.5401e-02,  1.7107e-02,\n",
       "          1.0625e-02,  1.3831e-02, -2.7095e-02,  2.6889e-02, -2.7886e-02,\n",
       "          1.8820e-02,  9.0302e-03,  1.9226e-02, -3.2337e-02,  3.3340e-03,\n",
       "          3.4475e-02,  4.0321e-02, -3.0111e-02, -3.7761e-02, -8.0048e-03,\n",
       "          3.3834e-02, -3.5227e-02, -2.0134e-02,  4.2054e-02,  4.4422e-02,\n",
       "          2.2993e-02, -3.8351e-02,  1.3729e-02, -4.3259e-02,  2.2394e-02,\n",
       "          1.5212e-02, -1.7709e-02,  5.1135e-03, -1.9202e-02, -1.9735e-02,\n",
       "          1.3355e-02,  3.0264e-02,  2.2126e-02, -4.4545e-02,  3.0135e-02,\n",
       "         -1.4815e-02,  4.0206e-02,  1.5779e-03,  3.8340e-02,  9.8473e-03,\n",
       "         -9.3811e-03, -1.2276e-02,  7.5916e-03, -1.9184e-02,  3.6282e-02,\n",
       "         -3.9329e-02,  1.4117e-02, -3.4375e-02, -4.0472e-02,  3.4529e-02,\n",
       "          1.4011e-02,  1.4562e-02,  1.5783e-03,  2.0359e-03, -1.7042e-02,\n",
       "         -3.9130e-02,  1.5329e-02, -4.4017e-02,  4.8297e-03,  4.4310e-02,\n",
       "         -1.8625e-02,  9.4668e-03,  3.1166e-02, -6.4128e-03,  1.5812e-02,\n",
       "          4.1620e-02, -1.8543e-02, -1.0681e-02,  4.2972e-02,  4.3708e-02,\n",
       "          8.0404e-03, -7.3850e-03,  2.5235e-03, -3.5513e-04,  4.2617e-02,\n",
       "          4.7378e-03, -6.4799e-04, -4.1823e-02, -4.2542e-02,  3.2666e-02,\n",
       "          1.3542e-02, -1.0647e-02,  2.6763e-02,  2.1066e-02,  2.5992e-02,\n",
       "         -2.8657e-02,  3.8587e-03, -3.0511e-02, -4.1069e-02,  2.2219e-02,\n",
       "         -1.4463e-04, -3.5777e-02, -1.4766e-02,  1.7049e-03, -6.5308e-03,\n",
       "          3.8848e-02, -3.8774e-02, -3.8691e-02,  7.3360e-03, -4.1994e-02,\n",
       "         -1.5414e-03, -1.4655e-02,  5.4779e-03, -3.4047e-02,  2.9518e-02,\n",
       "          3.9362e-02, -3.1712e-02,  3.8514e-02, -3.0513e-02,  4.0123e-02,\n",
       "         -1.2999e-02, -3.1919e-02, -1.2947e-02, -8.0082e-03,  4.2726e-02,\n",
       "         -1.5036e-02,  1.9933e-02, -9.1069e-03, -4.3835e-02,  4.2621e-02,\n",
       "         -1.4886e-02, -3.3990e-02,  2.5839e-02,  5.6705e-04, -7.5278e-03,\n",
       "          1.9683e-02, -2.1919e-02, -2.2849e-02,  3.9919e-02, -5.1283e-04,\n",
       "          8.0580e-03, -2.9618e-02,  3.7362e-02, -1.5029e-02, -3.4724e-02,\n",
       "         -3.3179e-03,  1.4193e-02,  2.9533e-02,  1.9853e-03, -2.3074e-02,\n",
       "          1.9268e-02, -1.9487e-02,  1.6634e-02,  1.1170e-02, -4.2041e-02,\n",
       "         -4.4470e-03, -2.3455e-02, -1.1193e-02,  2.8866e-02,  1.0357e-02,\n",
       "          3.9256e-02,  3.9106e-02,  9.6319e-03,  3.6837e-02,  8.9598e-03,\n",
       "         -3.4623e-02, -2.2752e-02, -1.4896e-02,  3.2906e-02, -3.1833e-02,\n",
       "         -2.3061e-02, -3.3207e-02,  3.4664e-02, -3.9667e-02, -3.4948e-02,\n",
       "          4.0896e-03,  4.2251e-02, -3.5774e-04, -6.6334e-03,  1.5424e-02,\n",
       "          2.6356e-02,  2.5695e-02, -2.9499e-02, -2.2395e-02,  3.2505e-02,\n",
       "          3.6782e-02, -1.3381e-02,  2.8417e-02,  8.7302e-03, -6.4409e-03,\n",
       "         -3.2618e-02, -1.0854e-02,  8.9898e-04, -2.9172e-02, -3.5870e-02,\n",
       "          4.3228e-03,  1.7088e-02, -4.0346e-02, -2.9533e-02, -2.9019e-02,\n",
       "          1.6307e-02, -1.2676e-02,  4.2133e-02,  6.3035e-03, -9.5179e-03,\n",
       "         -1.4693e-02, -1.4821e-02,  2.5618e-02, -3.9299e-02, -1.9317e-02,\n",
       "          3.2969e-02,  3.3600e-02,  3.9989e-02, -3.3297e-02,  2.0476e-02,\n",
       "          1.7852e-02,  2.2399e-02,  2.4068e-02, -7.2349e-03,  3.9720e-02,\n",
       "          1.7061e-02, -4.1427e-02,  2.6329e-02, -4.2471e-02, -4.0780e-02],\n",
       "        requires_grad=True)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1.weight',\n",
       "              tensor([[ 0.0289,  0.0207, -0.0158,  ...,  0.0181,  0.0082,  0.0071],\n",
       "                      [-0.0277,  0.0350,  0.0145,  ..., -0.0131,  0.0354, -0.0099],\n",
       "                      [ 0.0182,  0.0227, -0.0094,  ...,  0.0338, -0.0040, -0.0336],\n",
       "                      ...,\n",
       "                      [ 0.0134, -0.0242,  0.0159,  ...,  0.0244,  0.0152, -0.0095],\n",
       "                      [ 0.0265,  0.0196, -0.0347,  ..., -0.0337, -0.0344,  0.0017],\n",
       "                      [ 0.0112, -0.0045,  0.0262,  ...,  0.0193, -0.0022,  0.0070]])),\n",
       "             ('linear1.bias',\n",
       "              tensor([ 0.0241, -0.0367,  0.0284, -0.0128, -0.0097, -0.0328, -0.0102, -0.0323,\n",
       "                       0.0149, -0.0077, -0.0029, -0.0067,  0.0203,  0.0337, -0.0155, -0.0093,\n",
       "                      -0.0233,  0.0117,  0.0314, -0.0334,  0.0309,  0.0317,  0.0023,  0.0058,\n",
       "                       0.0257,  0.0281, -0.0123,  0.0087,  0.0104,  0.0271, -0.0232,  0.0362,\n",
       "                      -0.0047,  0.0171, -0.0191, -0.0034, -0.0196, -0.0101, -0.0352,  0.0341,\n",
       "                       0.0002, -0.0091,  0.0343, -0.0256, -0.0141, -0.0351, -0.0359, -0.0288,\n",
       "                      -0.0195, -0.0047,  0.0041,  0.0324,  0.0264, -0.0099,  0.0136,  0.0155,\n",
       "                       0.0227, -0.0182, -0.0272, -0.0321, -0.0187, -0.0180, -0.0207,  0.0233,\n",
       "                       0.0338,  0.0377,  0.0328,  0.0253, -0.0053,  0.0111, -0.0102,  0.0034,\n",
       "                      -0.0282,  0.0208,  0.0228,  0.0120, -0.0226, -0.0207, -0.0271, -0.0240,\n",
       "                       0.0135,  0.0186, -0.0122, -0.0080, -0.0304,  0.0248,  0.0096,  0.0179,\n",
       "                      -0.0257, -0.0166, -0.0071, -0.0293, -0.0194,  0.0092,  0.0256, -0.0063,\n",
       "                       0.0195,  0.0295, -0.0013,  0.0316, -0.0032,  0.0034,  0.0318, -0.0190,\n",
       "                      -0.0281,  0.0373, -0.0172,  0.0325, -0.0081, -0.0012, -0.0032,  0.0195,\n",
       "                       0.0182, -0.0141, -0.0060,  0.0099,  0.0374, -0.0094,  0.0126,  0.0026,\n",
       "                       0.0001,  0.0150,  0.0270, -0.0369, -0.0238, -0.0113, -0.0098,  0.0221,\n",
       "                      -0.0036,  0.0270,  0.0046,  0.0120, -0.0335, -0.0060,  0.0339,  0.0187,\n",
       "                      -0.0084, -0.0135, -0.0119,  0.0181, -0.0306, -0.0328,  0.0278,  0.0026,\n",
       "                       0.0139,  0.0258,  0.0043,  0.0078, -0.0066,  0.0068, -0.0257, -0.0069,\n",
       "                      -0.0068, -0.0027,  0.0340, -0.0203,  0.0065, -0.0331,  0.0249, -0.0261,\n",
       "                       0.0267, -0.0351,  0.0258, -0.0230,  0.0001, -0.0011,  0.0317,  0.0261,\n",
       "                       0.0360, -0.0351, -0.0263, -0.0014,  0.0339,  0.0069,  0.0039,  0.0269,\n",
       "                       0.0235, -0.0348, -0.0274,  0.0116,  0.0264,  0.0285, -0.0192, -0.0070,\n",
       "                       0.0344,  0.0064,  0.0376,  0.0342, -0.0223, -0.0173,  0.0370,  0.0332,\n",
       "                       0.0311,  0.0266, -0.0155, -0.0019,  0.0123, -0.0052, -0.0316, -0.0333,\n",
       "                      -0.0137, -0.0163, -0.0106, -0.0287,  0.0051,  0.0260,  0.0077,  0.0342,\n",
       "                      -0.0138,  0.0120,  0.0007,  0.0002, -0.0071, -0.0152,  0.0276,  0.0176,\n",
       "                       0.0055, -0.0089,  0.0324, -0.0176, -0.0223,  0.0199, -0.0271, -0.0074,\n",
       "                       0.0059, -0.0161, -0.0115,  0.0317, -0.0203, -0.0054,  0.0248, -0.0360,\n",
       "                      -0.0080,  0.0365,  0.0231,  0.0172, -0.0232,  0.0242, -0.0279,  0.0303,\n",
       "                      -0.0013, -0.0046, -0.0255,  0.0319, -0.0357, -0.0054,  0.0213,  0.0261,\n",
       "                       0.0076,  0.0310, -0.0318,  0.0340,  0.0142, -0.0029, -0.0276, -0.0093,\n",
       "                       0.0146,  0.0170,  0.0144,  0.0319,  0.0283, -0.0284,  0.0140,  0.0036,\n",
       "                      -0.0361, -0.0294, -0.0210,  0.0268, -0.0094, -0.0281,  0.0368,  0.0127,\n",
       "                      -0.0262, -0.0067,  0.0060,  0.0217,  0.0091, -0.0124,  0.0299,  0.0112,\n",
       "                       0.0177, -0.0048,  0.0061, -0.0272,  0.0348, -0.0234,  0.0250,  0.0118,\n",
       "                       0.0017, -0.0055,  0.0075, -0.0088,  0.0103, -0.0009,  0.0306, -0.0320,\n",
       "                      -0.0064,  0.0032,  0.0043, -0.0303,  0.0208,  0.0071,  0.0069, -0.0089,\n",
       "                       0.0172,  0.0023,  0.0317,  0.0189, -0.0303,  0.0211, -0.0333,  0.0274,\n",
       "                       0.0011, -0.0326, -0.0295,  0.0364, -0.0220, -0.0002,  0.0117,  0.0292,\n",
       "                      -0.0319, -0.0064, -0.0101, -0.0363, -0.0235, -0.0202,  0.0179, -0.0347,\n",
       "                      -0.0151,  0.0128, -0.0008, -0.0223,  0.0201, -0.0181, -0.0196,  0.0289,\n",
       "                      -0.0013, -0.0117, -0.0187,  0.0256, -0.0343,  0.0356, -0.0175, -0.0134,\n",
       "                      -0.0197,  0.0011, -0.0100,  0.0149,  0.0064, -0.0287,  0.0266,  0.0253,\n",
       "                      -0.0158,  0.0359,  0.0103,  0.0127, -0.0103,  0.0254,  0.0309,  0.0299,\n",
       "                      -0.0278,  0.0177, -0.0326,  0.0190, -0.0024, -0.0214,  0.0360, -0.0069,\n",
       "                      -0.0149, -0.0349, -0.0337,  0.0098, -0.0139, -0.0316, -0.0372,  0.0374,\n",
       "                       0.0121,  0.0344,  0.0290, -0.0286,  0.0043, -0.0214,  0.0252, -0.0345,\n",
       "                      -0.0073, -0.0373, -0.0185, -0.0041,  0.0369, -0.0112, -0.0350, -0.0168,\n",
       "                      -0.0311, -0.0025, -0.0186,  0.0072,  0.0159, -0.0118, -0.0291, -0.0314,\n",
       "                       0.0061,  0.0170, -0.0088, -0.0271, -0.0021, -0.0026, -0.0190,  0.0223,\n",
       "                       0.0180, -0.0200,  0.0028,  0.0295,  0.0143, -0.0092,  0.0030,  0.0251,\n",
       "                       0.0136, -0.0085, -0.0308, -0.0368, -0.0214,  0.0357,  0.0067,  0.0118,\n",
       "                       0.0011,  0.0026, -0.0187,  0.0031,  0.0110, -0.0368, -0.0092,  0.0235,\n",
       "                      -0.0277, -0.0280, -0.0267,  0.0170,  0.0156, -0.0130,  0.0101, -0.0270,\n",
       "                       0.0352, -0.0134,  0.0003,  0.0205,  0.0353, -0.0054,  0.0064, -0.0177,\n",
       "                       0.0329, -0.0187,  0.0276,  0.0259, -0.0133,  0.0184, -0.0274,  0.0194,\n",
       "                       0.0153, -0.0091,  0.0142,  0.0218,  0.0289, -0.0178, -0.0199, -0.0016,\n",
       "                       0.0152, -0.0311, -0.0106, -0.0068,  0.0222,  0.0187, -0.0180, -0.0010,\n",
       "                      -0.0213,  0.0114,  0.0244,  0.0079, -0.0081,  0.0037,  0.0222, -0.0088,\n",
       "                      -0.0300,  0.0004,  0.0151, -0.0360,  0.0142,  0.0343, -0.0093,  0.0347,\n",
       "                      -0.0136,  0.0196, -0.0281,  0.0030, -0.0358, -0.0143,  0.0333,  0.0118,\n",
       "                      -0.0147,  0.0187,  0.0354,  0.0249])),\n",
       "             ('linear3.weight',\n",
       "              tensor([[-0.0437,  0.0364,  0.0447,  ...,  0.0210, -0.0191, -0.0271],\n",
       "                      [ 0.0414, -0.0166,  0.0111,  ..., -0.0177,  0.0346,  0.0251],\n",
       "                      [-0.0006, -0.0332,  0.0008,  ...,  0.0310,  0.0443,  0.0023],\n",
       "                      ...,\n",
       "                      [ 0.0190,  0.0203, -0.0332,  ..., -0.0438, -0.0135, -0.0221],\n",
       "                      [ 0.0147, -0.0072, -0.0179,  ..., -0.0155,  0.0323,  0.0270],\n",
       "                      [ 0.0099, -0.0302,  0.0004,  ..., -0.0411, -0.0010, -0.0119]])),\n",
       "             ('linear3.bias',\n",
       "              tensor([ 0.0427, -0.0232, -0.0083,  0.0196, -0.0318,  0.0348, -0.0412,  0.0164,\n",
       "                      -0.0097, -0.0179])),\n",
       "             ('linear2.weight',\n",
       "              tensor([[-0.0186, -0.0304, -0.0207,  ..., -0.0041,  0.0185, -0.0173],\n",
       "                      [-0.0382, -0.0023, -0.0217,  ...,  0.0334, -0.0362,  0.0414],\n",
       "                      [ 0.0324, -0.0240, -0.0083,  ..., -0.0389,  0.0143, -0.0124],\n",
       "                      ...,\n",
       "                      [-0.0128,  0.0168,  0.0289,  ..., -0.0051, -0.0138, -0.0401],\n",
       "                      [ 0.0357,  0.0075, -0.0385,  ...,  0.0328, -0.0170,  0.0383],\n",
       "                      [-0.0350,  0.0442,  0.0409,  ...,  0.0017, -0.0089, -0.0119]])),\n",
       "             ('linear2.bias',\n",
       "              tensor([-1.7099e-03,  2.1052e-02,  3.1905e-03,  9.6159e-03,  2.1035e-02,\n",
       "                      -2.1277e-02,  1.2616e-02, -3.0824e-02,  2.7923e-02,  4.3028e-02,\n",
       "                      -4.4171e-02,  3.9664e-02, -1.2370e-02, -2.1143e-02, -2.4324e-02,\n",
       "                       3.2168e-02,  1.8225e-02,  9.4844e-03,  4.2564e-02, -3.3345e-02,\n",
       "                       1.0905e-02,  3.9634e-02,  2.4935e-02, -1.3114e-02, -7.2429e-03,\n",
       "                       1.9432e-02, -1.9760e-02, -2.1420e-02,  1.4277e-02, -4.3666e-02,\n",
       "                       3.7850e-03, -2.8832e-02,  1.0270e-02,  7.7023e-03, -2.3948e-05,\n",
       "                       1.9982e-02,  4.0204e-02, -2.5552e-02, -3.8806e-02,  2.3297e-02,\n",
       "                       1.8551e-02, -3.5196e-02,  4.4553e-02, -4.4459e-03,  1.6922e-02,\n",
       "                      -2.4501e-02, -2.4812e-02, -3.6928e-02, -1.7975e-02,  8.2489e-04,\n",
       "                       4.0318e-02,  2.7931e-02, -2.1893e-03, -1.7749e-02,  1.7442e-02,\n",
       "                      -1.0218e-02,  2.7889e-04, -1.5717e-02,  2.2628e-02, -2.7281e-03,\n",
       "                      -4.0731e-02,  2.0459e-02,  7.2801e-04, -3.7180e-02,  1.2595e-02,\n",
       "                       2.3330e-02, -2.6614e-02,  2.7255e-02, -3.7461e-02,  4.0688e-02,\n",
       "                      -1.3176e-02,  1.6109e-02, -9.1315e-03,  5.4194e-03,  6.9129e-03,\n",
       "                      -5.3092e-03, -4.3527e-02,  2.2829e-02,  7.7954e-04,  3.3675e-02,\n",
       "                       1.0872e-02,  2.2892e-02, -3.4833e-02, -7.7667e-03, -1.6867e-02,\n",
       "                       4.6024e-03, -4.2890e-02, -2.0887e-02,  1.9243e-02,  3.5871e-02,\n",
       "                       1.3244e-02, -2.6405e-02,  1.9951e-02,  1.4831e-02,  3.1961e-02,\n",
       "                      -6.1723e-03,  2.1000e-02,  2.8997e-02, -3.8450e-02,  3.5310e-03,\n",
       "                       4.4518e-02, -2.3697e-02,  1.1044e-02, -7.7797e-03,  1.5449e-02,\n",
       "                       3.9487e-02, -4.4446e-02,  3.6269e-02,  1.5969e-02, -9.1293e-03,\n",
       "                       1.3271e-02, -2.5626e-02,  3.6445e-02, -3.2636e-03,  1.0259e-02,\n",
       "                       2.7223e-02, -3.6353e-02,  9.4154e-03, -2.2741e-02,  4.3404e-02,\n",
       "                      -3.4709e-02, -1.2919e-02, -3.5713e-02,  2.1364e-02, -1.9060e-03,\n",
       "                      -1.1253e-02, -2.5161e-02,  3.0309e-02,  9.2230e-05,  1.0513e-02,\n",
       "                      -3.6416e-02,  8.5248e-03, -2.9330e-02,  1.3905e-02, -1.0323e-02,\n",
       "                       1.1527e-02, -4.3624e-02, -1.3992e-02, -4.6646e-03,  1.0019e-02,\n",
       "                      -1.1894e-02,  1.0935e-02, -4.1484e-02,  2.9089e-02,  1.9597e-02,\n",
       "                       3.1194e-02,  1.9316e-02, -4.3188e-02, -3.2368e-02,  9.0949e-04,\n",
       "                       3.5931e-02,  2.8776e-02, -4.1996e-02,  3.5485e-02,  1.1613e-04,\n",
       "                      -6.1483e-03,  3.6123e-03,  6.7525e-03,  3.1756e-02, -4.1268e-02,\n",
       "                      -3.4749e-02, -1.1682e-02,  1.3065e-02,  3.4541e-02, -3.9750e-02,\n",
       "                       1.3085e-02,  1.7107e-04,  7.0596e-03, -1.5638e-02,  3.8069e-02,\n",
       "                       3.2486e-03,  2.9219e-02,  3.9740e-02,  2.8430e-02,  7.4506e-03,\n",
       "                      -6.6614e-03, -3.0603e-02,  1.2114e-02, -1.0091e-02, -7.5613e-04,\n",
       "                       3.4938e-02, -3.3526e-03, -4.6702e-03, -3.7593e-02, -1.6819e-02,\n",
       "                      -1.3045e-03, -2.7303e-03, -1.8369e-02, -1.3325e-02,  6.7699e-03,\n",
       "                      -3.9553e-02,  1.7264e-02, -1.8990e-02,  2.2401e-02,  5.4209e-03,\n",
       "                       1.2127e-02, -2.7636e-02,  1.4569e-02,  1.0620e-02, -5.2207e-03,\n",
       "                       3.8062e-02,  2.0032e-02, -5.3433e-03, -1.1164e-02, -3.5192e-02,\n",
       "                       3.8284e-02,  1.2538e-02, -2.2300e-02,  4.1490e-03, -1.7349e-02,\n",
       "                      -1.5826e-02,  5.9756e-03,  2.8643e-02,  1.4909e-02, -2.6151e-02,\n",
       "                       3.0213e-02,  2.3574e-02,  8.4391e-03, -2.3906e-02, -4.7402e-03,\n",
       "                      -4.4011e-02, -1.9569e-02, -3.7633e-02, -4.3908e-02, -4.2854e-02,\n",
       "                       1.6734e-02, -2.9000e-02,  2.6444e-02, -3.5762e-02, -8.8302e-03,\n",
       "                      -1.0815e-02, -5.6124e-03, -8.4059e-03, -3.4946e-03,  2.9838e-02,\n",
       "                       1.5598e-03,  3.2988e-02, -6.3099e-03, -2.2818e-02,  1.4727e-03,\n",
       "                      -1.3798e-02,  1.0278e-02, -4.3593e-02,  2.0276e-02, -3.5138e-02,\n",
       "                      -1.1949e-02,  1.5883e-02,  3.5919e-02, -3.7085e-03, -3.7121e-02,\n",
       "                      -4.3184e-02,  3.3894e-02,  2.7983e-02,  2.1476e-02,  1.5536e-03,\n",
       "                      -1.9854e-02,  2.7252e-02, -3.1548e-03,  3.7671e-02, -3.3659e-02,\n",
       "                      -2.6127e-02,  6.7954e-03, -1.1486e-02, -2.0796e-02, -2.8710e-02,\n",
       "                      -1.8864e-02, -7.4169e-03, -5.7270e-03,  4.2847e-02, -2.9568e-02,\n",
       "                      -1.6526e-02, -1.9685e-02,  4.2677e-02, -4.7691e-04, -3.1012e-02,\n",
       "                      -1.6628e-02, -1.8322e-02,  2.3220e-02,  8.4451e-03,  3.7875e-02,\n",
       "                       2.0523e-02, -2.7545e-02, -4.2705e-02, -3.5401e-02,  1.7107e-02,\n",
       "                       1.0625e-02,  1.3831e-02, -2.7095e-02,  2.6889e-02, -2.7886e-02,\n",
       "                       1.8820e-02,  9.0302e-03,  1.9226e-02, -3.2337e-02,  3.3340e-03,\n",
       "                       3.4475e-02,  4.0321e-02, -3.0111e-02, -3.7761e-02, -8.0048e-03,\n",
       "                       3.3834e-02, -3.5227e-02, -2.0134e-02,  4.2054e-02,  4.4422e-02,\n",
       "                       2.2993e-02, -3.8351e-02,  1.3729e-02, -4.3259e-02,  2.2394e-02,\n",
       "                       1.5212e-02, -1.7709e-02,  5.1135e-03, -1.9202e-02, -1.9735e-02,\n",
       "                       1.3355e-02,  3.0264e-02,  2.2126e-02, -4.4545e-02,  3.0135e-02,\n",
       "                      -1.4815e-02,  4.0206e-02,  1.5779e-03,  3.8340e-02,  9.8473e-03,\n",
       "                      -9.3811e-03, -1.2276e-02,  7.5916e-03, -1.9184e-02,  3.6282e-02,\n",
       "                      -3.9329e-02,  1.4117e-02, -3.4375e-02, -4.0472e-02,  3.4529e-02,\n",
       "                       1.4011e-02,  1.4562e-02,  1.5783e-03,  2.0359e-03, -1.7042e-02,\n",
       "                      -3.9130e-02,  1.5329e-02, -4.4017e-02,  4.8297e-03,  4.4310e-02,\n",
       "                      -1.8625e-02,  9.4668e-03,  3.1166e-02, -6.4128e-03,  1.5812e-02,\n",
       "                       4.1620e-02, -1.8543e-02, -1.0681e-02,  4.2972e-02,  4.3708e-02,\n",
       "                       8.0404e-03, -7.3850e-03,  2.5235e-03, -3.5513e-04,  4.2617e-02,\n",
       "                       4.7378e-03, -6.4799e-04, -4.1823e-02, -4.2542e-02,  3.2666e-02,\n",
       "                       1.3542e-02, -1.0647e-02,  2.6763e-02,  2.1066e-02,  2.5992e-02,\n",
       "                      -2.8657e-02,  3.8587e-03, -3.0511e-02, -4.1069e-02,  2.2219e-02,\n",
       "                      -1.4463e-04, -3.5777e-02, -1.4766e-02,  1.7049e-03, -6.5308e-03,\n",
       "                       3.8848e-02, -3.8774e-02, -3.8691e-02,  7.3360e-03, -4.1994e-02,\n",
       "                      -1.5414e-03, -1.4655e-02,  5.4779e-03, -3.4047e-02,  2.9518e-02,\n",
       "                       3.9362e-02, -3.1712e-02,  3.8514e-02, -3.0513e-02,  4.0123e-02,\n",
       "                      -1.2999e-02, -3.1919e-02, -1.2947e-02, -8.0082e-03,  4.2726e-02,\n",
       "                      -1.5036e-02,  1.9933e-02, -9.1069e-03, -4.3835e-02,  4.2621e-02,\n",
       "                      -1.4886e-02, -3.3990e-02,  2.5839e-02,  5.6705e-04, -7.5278e-03,\n",
       "                       1.9683e-02, -2.1919e-02, -2.2849e-02,  3.9919e-02, -5.1283e-04,\n",
       "                       8.0580e-03, -2.9618e-02,  3.7362e-02, -1.5029e-02, -3.4724e-02,\n",
       "                      -3.3179e-03,  1.4193e-02,  2.9533e-02,  1.9853e-03, -2.3074e-02,\n",
       "                       1.9268e-02, -1.9487e-02,  1.6634e-02,  1.1170e-02, -4.2041e-02,\n",
       "                      -4.4470e-03, -2.3455e-02, -1.1193e-02,  2.8866e-02,  1.0357e-02,\n",
       "                       3.9256e-02,  3.9106e-02,  9.6319e-03,  3.6837e-02,  8.9598e-03,\n",
       "                      -3.4623e-02, -2.2752e-02, -1.4896e-02,  3.2906e-02, -3.1833e-02,\n",
       "                      -2.3061e-02, -3.3207e-02,  3.4664e-02, -3.9667e-02, -3.4948e-02,\n",
       "                       4.0896e-03,  4.2251e-02, -3.5774e-04, -6.6334e-03,  1.5424e-02,\n",
       "                       2.6356e-02,  2.5695e-02, -2.9499e-02, -2.2395e-02,  3.2505e-02,\n",
       "                       3.6782e-02, -1.3381e-02,  2.8417e-02,  8.7302e-03, -6.4409e-03,\n",
       "                      -3.2618e-02, -1.0854e-02,  8.9898e-04, -2.9172e-02, -3.5870e-02,\n",
       "                       4.3228e-03,  1.7088e-02, -4.0346e-02, -2.9533e-02, -2.9019e-02,\n",
       "                       1.6307e-02, -1.2676e-02,  4.2133e-02,  6.3035e-03, -9.5179e-03,\n",
       "                      -1.4693e-02, -1.4821e-02,  2.5618e-02, -3.9299e-02, -1.9317e-02,\n",
       "                       3.2969e-02,  3.3600e-02,  3.9989e-02, -3.3297e-02,  2.0476e-02,\n",
       "                       1.7852e-02,  2.2399e-02,  2.4068e-02, -7.2349e-03,  3.9720e-02,\n",
       "                       1.7061e-02, -4.1427e-02,  2.6329e-02, -4.2471e-02, -4.0780e-02]))])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('linear1.weight',\n",
       "              tensor([[ 0.0289,  0.0207, -0.0158,  ...,  0.0181,  0.0082,  0.0071],\n",
       "                      [-0.0277,  0.0350,  0.0145,  ..., -0.0131,  0.0354, -0.0099],\n",
       "                      [ 0.0182,  0.0227, -0.0094,  ...,  0.0338, -0.0040, -0.0336],\n",
       "                      ...,\n",
       "                      [ 0.0134, -0.0242,  0.0159,  ...,  0.0244,  0.0152, -0.0095],\n",
       "                      [ 0.0265,  0.0196, -0.0347,  ..., -0.0337, -0.0344,  0.0017],\n",
       "                      [ 0.0112, -0.0045,  0.0262,  ...,  0.0193, -0.0022,  0.0070]])),\n",
       "             ('linear1.bias',\n",
       "              tensor([ 0.0241, -0.0367,  0.0284, -0.0128, -0.0097, -0.0328, -0.0102, -0.0323,\n",
       "                       0.0149, -0.0077, -0.0029, -0.0067,  0.0203,  0.0337, -0.0155, -0.0093,\n",
       "                      -0.0233,  0.0117,  0.0314, -0.0334,  0.0309,  0.0317,  0.0023,  0.0058,\n",
       "                       0.0257,  0.0281, -0.0123,  0.0087,  0.0104,  0.0271, -0.0232,  0.0362,\n",
       "                      -0.0047,  0.0171, -0.0191, -0.0034, -0.0196, -0.0101, -0.0352,  0.0341,\n",
       "                       0.0002, -0.0091,  0.0343, -0.0256, -0.0141, -0.0351, -0.0359, -0.0288,\n",
       "                      -0.0195, -0.0047,  0.0041,  0.0324,  0.0264, -0.0099,  0.0136,  0.0155,\n",
       "                       0.0227, -0.0182, -0.0272, -0.0321, -0.0187, -0.0180, -0.0207,  0.0233,\n",
       "                       0.0338,  0.0377,  0.0328,  0.0253, -0.0053,  0.0111, -0.0102,  0.0034,\n",
       "                      -0.0282,  0.0208,  0.0228,  0.0120, -0.0226, -0.0207, -0.0271, -0.0240,\n",
       "                       0.0135,  0.0186, -0.0122, -0.0080, -0.0304,  0.0248,  0.0096,  0.0179,\n",
       "                      -0.0257, -0.0166, -0.0071, -0.0293, -0.0194,  0.0092,  0.0256, -0.0063,\n",
       "                       0.0195,  0.0295, -0.0013,  0.0316, -0.0032,  0.0034,  0.0318, -0.0190,\n",
       "                      -0.0281,  0.0373, -0.0172,  0.0325, -0.0081, -0.0012, -0.0032,  0.0195,\n",
       "                       0.0182, -0.0141, -0.0060,  0.0099,  0.0374, -0.0094,  0.0126,  0.0026,\n",
       "                       0.0001,  0.0150,  0.0270, -0.0369, -0.0238, -0.0113, -0.0098,  0.0221,\n",
       "                      -0.0036,  0.0270,  0.0046,  0.0120, -0.0335, -0.0060,  0.0339,  0.0187,\n",
       "                      -0.0084, -0.0135, -0.0119,  0.0181, -0.0306, -0.0328,  0.0278,  0.0026,\n",
       "                       0.0139,  0.0258,  0.0043,  0.0078, -0.0066,  0.0068, -0.0257, -0.0069,\n",
       "                      -0.0068, -0.0027,  0.0340, -0.0203,  0.0065, -0.0331,  0.0249, -0.0261,\n",
       "                       0.0267, -0.0351,  0.0258, -0.0230,  0.0001, -0.0011,  0.0317,  0.0261,\n",
       "                       0.0360, -0.0351, -0.0263, -0.0014,  0.0339,  0.0069,  0.0039,  0.0269,\n",
       "                       0.0235, -0.0348, -0.0274,  0.0116,  0.0264,  0.0285, -0.0192, -0.0070,\n",
       "                       0.0344,  0.0064,  0.0376,  0.0342, -0.0223, -0.0173,  0.0370,  0.0332,\n",
       "                       0.0311,  0.0266, -0.0155, -0.0019,  0.0123, -0.0052, -0.0316, -0.0333,\n",
       "                      -0.0137, -0.0163, -0.0106, -0.0287,  0.0051,  0.0260,  0.0077,  0.0342,\n",
       "                      -0.0138,  0.0120,  0.0007,  0.0002, -0.0071, -0.0152,  0.0276,  0.0176,\n",
       "                       0.0055, -0.0089,  0.0324, -0.0176, -0.0223,  0.0199, -0.0271, -0.0074,\n",
       "                       0.0059, -0.0161, -0.0115,  0.0317, -0.0203, -0.0054,  0.0248, -0.0360,\n",
       "                      -0.0080,  0.0365,  0.0231,  0.0172, -0.0232,  0.0242, -0.0279,  0.0303,\n",
       "                      -0.0013, -0.0046, -0.0255,  0.0319, -0.0357, -0.0054,  0.0213,  0.0261,\n",
       "                       0.0076,  0.0310, -0.0318,  0.0340,  0.0142, -0.0029, -0.0276, -0.0093,\n",
       "                       0.0146,  0.0170,  0.0144,  0.0319,  0.0283, -0.0284,  0.0140,  0.0036,\n",
       "                      -0.0361, -0.0294, -0.0210,  0.0268, -0.0094, -0.0281,  0.0368,  0.0127,\n",
       "                      -0.0262, -0.0067,  0.0060,  0.0217,  0.0091, -0.0124,  0.0299,  0.0112,\n",
       "                       0.0177, -0.0048,  0.0061, -0.0272,  0.0348, -0.0234,  0.0250,  0.0118,\n",
       "                       0.0017, -0.0055,  0.0075, -0.0088,  0.0103, -0.0009,  0.0306, -0.0320,\n",
       "                      -0.0064,  0.0032,  0.0043, -0.0303,  0.0208,  0.0071,  0.0069, -0.0089,\n",
       "                       0.0172,  0.0023,  0.0317,  0.0189, -0.0303,  0.0211, -0.0333,  0.0274,\n",
       "                       0.0011, -0.0326, -0.0295,  0.0364, -0.0220, -0.0002,  0.0117,  0.0292,\n",
       "                      -0.0319, -0.0064, -0.0101, -0.0363, -0.0235, -0.0202,  0.0179, -0.0347,\n",
       "                      -0.0151,  0.0128, -0.0008, -0.0223,  0.0201, -0.0181, -0.0196,  0.0289,\n",
       "                      -0.0013, -0.0117, -0.0187,  0.0256, -0.0343,  0.0356, -0.0175, -0.0134,\n",
       "                      -0.0197,  0.0011, -0.0100,  0.0149,  0.0064, -0.0287,  0.0266,  0.0253,\n",
       "                      -0.0158,  0.0359,  0.0103,  0.0127, -0.0103,  0.0254,  0.0309,  0.0299,\n",
       "                      -0.0278,  0.0177, -0.0326,  0.0190, -0.0024, -0.0214,  0.0360, -0.0069,\n",
       "                      -0.0149, -0.0349, -0.0337,  0.0098, -0.0139, -0.0316, -0.0372,  0.0374,\n",
       "                       0.0121,  0.0344,  0.0290, -0.0286,  0.0043, -0.0214,  0.0252, -0.0345,\n",
       "                      -0.0073, -0.0373, -0.0185, -0.0041,  0.0369, -0.0112, -0.0350, -0.0168,\n",
       "                      -0.0311, -0.0025, -0.0186,  0.0072,  0.0159, -0.0118, -0.0291, -0.0314,\n",
       "                       0.0061,  0.0170, -0.0088, -0.0271, -0.0021, -0.0026, -0.0190,  0.0223,\n",
       "                       0.0180, -0.0200,  0.0028,  0.0295,  0.0143, -0.0092,  0.0030,  0.0251,\n",
       "                       0.0136, -0.0085, -0.0308, -0.0368, -0.0214,  0.0357,  0.0067,  0.0118,\n",
       "                       0.0011,  0.0026, -0.0187,  0.0031,  0.0110, -0.0368, -0.0092,  0.0235,\n",
       "                      -0.0277, -0.0280, -0.0267,  0.0170,  0.0156, -0.0130,  0.0101, -0.0270,\n",
       "                       0.0352, -0.0134,  0.0003,  0.0205,  0.0353, -0.0054,  0.0064, -0.0177,\n",
       "                       0.0329, -0.0187,  0.0276,  0.0259, -0.0133,  0.0184, -0.0274,  0.0194,\n",
       "                       0.0153, -0.0091,  0.0142,  0.0218,  0.0289, -0.0178, -0.0199, -0.0016,\n",
       "                       0.0152, -0.0311, -0.0106, -0.0068,  0.0222,  0.0187, -0.0180, -0.0010,\n",
       "                      -0.0213,  0.0114,  0.0244,  0.0079, -0.0081,  0.0037,  0.0222, -0.0088,\n",
       "                      -0.0300,  0.0004,  0.0151, -0.0360,  0.0142,  0.0343, -0.0093,  0.0347,\n",
       "                      -0.0136,  0.0196, -0.0281,  0.0030, -0.0358, -0.0143,  0.0333,  0.0118,\n",
       "                      -0.0147,  0.0187,  0.0354,  0.0249])),\n",
       "             ('linear3.weight',\n",
       "              tensor([[-0.0437,  0.0364,  0.0447,  ...,  0.0210, -0.0191, -0.0271],\n",
       "                      [ 0.0414, -0.0166,  0.0111,  ..., -0.0177,  0.0346,  0.0251],\n",
       "                      [-0.0006, -0.0332,  0.0008,  ...,  0.0310,  0.0443,  0.0023],\n",
       "                      ...,\n",
       "                      [ 0.0190,  0.0203, -0.0332,  ..., -0.0438, -0.0135, -0.0221],\n",
       "                      [ 0.0147, -0.0072, -0.0179,  ..., -0.0155,  0.0323,  0.0270],\n",
       "                      [ 0.0099, -0.0302,  0.0004,  ..., -0.0411, -0.0010, -0.0119]])),\n",
       "             ('linear3.bias',\n",
       "              tensor([ 0.0427, -0.0232, -0.0083,  0.0196, -0.0318,  0.0348, -0.0412,  0.0164,\n",
       "                      -0.0097, -0.0179])),\n",
       "             ('linear2.weight',\n",
       "              tensor([[-0.0186, -0.0304, -0.0207,  ..., -0.0041,  0.0185, -0.0173],\n",
       "                      [-0.0382, -0.0023, -0.0217,  ...,  0.0334, -0.0362,  0.0414],\n",
       "                      [ 0.0324, -0.0240, -0.0083,  ..., -0.0389,  0.0143, -0.0124],\n",
       "                      ...,\n",
       "                      [-0.0128,  0.0168,  0.0289,  ..., -0.0051, -0.0138, -0.0401],\n",
       "                      [ 0.0357,  0.0075, -0.0385,  ...,  0.0328, -0.0170,  0.0383],\n",
       "                      [-0.0350,  0.0442,  0.0409,  ...,  0.0017, -0.0089, -0.0119]])),\n",
       "             ('linear2.bias',\n",
       "              tensor([-1.7099e-03,  2.1052e-02,  3.1905e-03,  9.6159e-03,  2.1035e-02,\n",
       "                      -2.1277e-02,  1.2616e-02, -3.0824e-02,  2.7923e-02,  4.3028e-02,\n",
       "                      -4.4171e-02,  3.9664e-02, -1.2370e-02, -2.1143e-02, -2.4324e-02,\n",
       "                       3.2168e-02,  1.8225e-02,  9.4844e-03,  4.2564e-02, -3.3345e-02,\n",
       "                       1.0905e-02,  3.9634e-02,  2.4935e-02, -1.3114e-02, -7.2429e-03,\n",
       "                       1.9432e-02, -1.9760e-02, -2.1420e-02,  1.4277e-02, -4.3666e-02,\n",
       "                       3.7850e-03, -2.8832e-02,  1.0270e-02,  7.7023e-03, -2.3948e-05,\n",
       "                       1.9982e-02,  4.0204e-02, -2.5552e-02, -3.8806e-02,  2.3297e-02,\n",
       "                       1.8551e-02, -3.5196e-02,  4.4553e-02, -4.4459e-03,  1.6922e-02,\n",
       "                      -2.4501e-02, -2.4812e-02, -3.6928e-02, -1.7975e-02,  8.2489e-04,\n",
       "                       4.0318e-02,  2.7931e-02, -2.1893e-03, -1.7749e-02,  1.7442e-02,\n",
       "                      -1.0218e-02,  2.7889e-04, -1.5717e-02,  2.2628e-02, -2.7281e-03,\n",
       "                      -4.0731e-02,  2.0459e-02,  7.2801e-04, -3.7180e-02,  1.2595e-02,\n",
       "                       2.3330e-02, -2.6614e-02,  2.7255e-02, -3.7461e-02,  4.0688e-02,\n",
       "                      -1.3176e-02,  1.6109e-02, -9.1315e-03,  5.4194e-03,  6.9129e-03,\n",
       "                      -5.3092e-03, -4.3527e-02,  2.2829e-02,  7.7954e-04,  3.3675e-02,\n",
       "                       1.0872e-02,  2.2892e-02, -3.4833e-02, -7.7667e-03, -1.6867e-02,\n",
       "                       4.6024e-03, -4.2890e-02, -2.0887e-02,  1.9243e-02,  3.5871e-02,\n",
       "                       1.3244e-02, -2.6405e-02,  1.9951e-02,  1.4831e-02,  3.1961e-02,\n",
       "                      -6.1723e-03,  2.1000e-02,  2.8997e-02, -3.8450e-02,  3.5310e-03,\n",
       "                       4.4518e-02, -2.3697e-02,  1.1044e-02, -7.7797e-03,  1.5449e-02,\n",
       "                       3.9487e-02, -4.4446e-02,  3.6269e-02,  1.5969e-02, -9.1293e-03,\n",
       "                       1.3271e-02, -2.5626e-02,  3.6445e-02, -3.2636e-03,  1.0259e-02,\n",
       "                       2.7223e-02, -3.6353e-02,  9.4154e-03, -2.2741e-02,  4.3404e-02,\n",
       "                      -3.4709e-02, -1.2919e-02, -3.5713e-02,  2.1364e-02, -1.9060e-03,\n",
       "                      -1.1253e-02, -2.5161e-02,  3.0309e-02,  9.2230e-05,  1.0513e-02,\n",
       "                      -3.6416e-02,  8.5248e-03, -2.9330e-02,  1.3905e-02, -1.0323e-02,\n",
       "                       1.1527e-02, -4.3624e-02, -1.3992e-02, -4.6646e-03,  1.0019e-02,\n",
       "                      -1.1894e-02,  1.0935e-02, -4.1484e-02,  2.9089e-02,  1.9597e-02,\n",
       "                       3.1194e-02,  1.9316e-02, -4.3188e-02, -3.2368e-02,  9.0949e-04,\n",
       "                       3.5931e-02,  2.8776e-02, -4.1996e-02,  3.5485e-02,  1.1613e-04,\n",
       "                      -6.1483e-03,  3.6123e-03,  6.7525e-03,  3.1756e-02, -4.1268e-02,\n",
       "                      -3.4749e-02, -1.1682e-02,  1.3065e-02,  3.4541e-02, -3.9750e-02,\n",
       "                       1.3085e-02,  1.7107e-04,  7.0596e-03, -1.5638e-02,  3.8069e-02,\n",
       "                       3.2486e-03,  2.9219e-02,  3.9740e-02,  2.8430e-02,  7.4506e-03,\n",
       "                      -6.6614e-03, -3.0603e-02,  1.2114e-02, -1.0091e-02, -7.5613e-04,\n",
       "                       3.4938e-02, -3.3526e-03, -4.6702e-03, -3.7593e-02, -1.6819e-02,\n",
       "                      -1.3045e-03, -2.7303e-03, -1.8369e-02, -1.3325e-02,  6.7699e-03,\n",
       "                      -3.9553e-02,  1.7264e-02, -1.8990e-02,  2.2401e-02,  5.4209e-03,\n",
       "                       1.2127e-02, -2.7636e-02,  1.4569e-02,  1.0620e-02, -5.2207e-03,\n",
       "                       3.8062e-02,  2.0032e-02, -5.3433e-03, -1.1164e-02, -3.5192e-02,\n",
       "                       3.8284e-02,  1.2538e-02, -2.2300e-02,  4.1490e-03, -1.7349e-02,\n",
       "                      -1.5826e-02,  5.9756e-03,  2.8643e-02,  1.4909e-02, -2.6151e-02,\n",
       "                       3.0213e-02,  2.3574e-02,  8.4391e-03, -2.3906e-02, -4.7402e-03,\n",
       "                      -4.4011e-02, -1.9569e-02, -3.7633e-02, -4.3908e-02, -4.2854e-02,\n",
       "                       1.6734e-02, -2.9000e-02,  2.6444e-02, -3.5762e-02, -8.8302e-03,\n",
       "                      -1.0815e-02, -5.6124e-03, -8.4059e-03, -3.4946e-03,  2.9838e-02,\n",
       "                       1.5598e-03,  3.2988e-02, -6.3099e-03, -2.2818e-02,  1.4727e-03,\n",
       "                      -1.3798e-02,  1.0278e-02, -4.3593e-02,  2.0276e-02, -3.5138e-02,\n",
       "                      -1.1949e-02,  1.5883e-02,  3.5919e-02, -3.7085e-03, -3.7121e-02,\n",
       "                      -4.3184e-02,  3.3894e-02,  2.7983e-02,  2.1476e-02,  1.5536e-03,\n",
       "                      -1.9854e-02,  2.7252e-02, -3.1548e-03,  3.7671e-02, -3.3659e-02,\n",
       "                      -2.6127e-02,  6.7954e-03, -1.1486e-02, -2.0796e-02, -2.8710e-02,\n",
       "                      -1.8864e-02, -7.4169e-03, -5.7270e-03,  4.2847e-02, -2.9568e-02,\n",
       "                      -1.6526e-02, -1.9685e-02,  4.2677e-02, -4.7691e-04, -3.1012e-02,\n",
       "                      -1.6628e-02, -1.8322e-02,  2.3220e-02,  8.4451e-03,  3.7875e-02,\n",
       "                       2.0523e-02, -2.7545e-02, -4.2705e-02, -3.5401e-02,  1.7107e-02,\n",
       "                       1.0625e-02,  1.3831e-02, -2.7095e-02,  2.6889e-02, -2.7886e-02,\n",
       "                       1.8820e-02,  9.0302e-03,  1.9226e-02, -3.2337e-02,  3.3340e-03,\n",
       "                       3.4475e-02,  4.0321e-02, -3.0111e-02, -3.7761e-02, -8.0048e-03,\n",
       "                       3.3834e-02, -3.5227e-02, -2.0134e-02,  4.2054e-02,  4.4422e-02,\n",
       "                       2.2993e-02, -3.8351e-02,  1.3729e-02, -4.3259e-02,  2.2394e-02,\n",
       "                       1.5212e-02, -1.7709e-02,  5.1135e-03, -1.9202e-02, -1.9735e-02,\n",
       "                       1.3355e-02,  3.0264e-02,  2.2126e-02, -4.4545e-02,  3.0135e-02,\n",
       "                      -1.4815e-02,  4.0206e-02,  1.5779e-03,  3.8340e-02,  9.8473e-03,\n",
       "                      -9.3811e-03, -1.2276e-02,  7.5916e-03, -1.9184e-02,  3.6282e-02,\n",
       "                      -3.9329e-02,  1.4117e-02, -3.4375e-02, -4.0472e-02,  3.4529e-02,\n",
       "                       1.4011e-02,  1.4562e-02,  1.5783e-03,  2.0359e-03, -1.7042e-02,\n",
       "                      -3.9130e-02,  1.5329e-02, -4.4017e-02,  4.8297e-03,  4.4310e-02,\n",
       "                      -1.8625e-02,  9.4668e-03,  3.1166e-02, -6.4128e-03,  1.5812e-02,\n",
       "                       4.1620e-02, -1.8543e-02, -1.0681e-02,  4.2972e-02,  4.3708e-02,\n",
       "                       8.0404e-03, -7.3850e-03,  2.5235e-03, -3.5513e-04,  4.2617e-02,\n",
       "                       4.7378e-03, -6.4799e-04, -4.1823e-02, -4.2542e-02,  3.2666e-02,\n",
       "                       1.3542e-02, -1.0647e-02,  2.6763e-02,  2.1066e-02,  2.5992e-02,\n",
       "                      -2.8657e-02,  3.8587e-03, -3.0511e-02, -4.1069e-02,  2.2219e-02,\n",
       "                      -1.4463e-04, -3.5777e-02, -1.4766e-02,  1.7049e-03, -6.5308e-03,\n",
       "                       3.8848e-02, -3.8774e-02, -3.8691e-02,  7.3360e-03, -4.1994e-02,\n",
       "                      -1.5414e-03, -1.4655e-02,  5.4779e-03, -3.4047e-02,  2.9518e-02,\n",
       "                       3.9362e-02, -3.1712e-02,  3.8514e-02, -3.0513e-02,  4.0123e-02,\n",
       "                      -1.2999e-02, -3.1919e-02, -1.2947e-02, -8.0082e-03,  4.2726e-02,\n",
       "                      -1.5036e-02,  1.9933e-02, -9.1069e-03, -4.3835e-02,  4.2621e-02,\n",
       "                      -1.4886e-02, -3.3990e-02,  2.5839e-02,  5.6705e-04, -7.5278e-03,\n",
       "                       1.9683e-02, -2.1919e-02, -2.2849e-02,  3.9919e-02, -5.1283e-04,\n",
       "                       8.0580e-03, -2.9618e-02,  3.7362e-02, -1.5029e-02, -3.4724e-02,\n",
       "                      -3.3179e-03,  1.4193e-02,  2.9533e-02,  1.9853e-03, -2.3074e-02,\n",
       "                       1.9268e-02, -1.9487e-02,  1.6634e-02,  1.1170e-02, -4.2041e-02,\n",
       "                      -4.4470e-03, -2.3455e-02, -1.1193e-02,  2.8866e-02,  1.0357e-02,\n",
       "                       3.9256e-02,  3.9106e-02,  9.6319e-03,  3.6837e-02,  8.9598e-03,\n",
       "                      -3.4623e-02, -2.2752e-02, -1.4896e-02,  3.2906e-02, -3.1833e-02,\n",
       "                      -2.3061e-02, -3.3207e-02,  3.4664e-02, -3.9667e-02, -3.4948e-02,\n",
       "                       4.0896e-03,  4.2251e-02, -3.5774e-04, -6.6334e-03,  1.5424e-02,\n",
       "                       2.6356e-02,  2.5695e-02, -2.9499e-02, -2.2395e-02,  3.2505e-02,\n",
       "                       3.6782e-02, -1.3381e-02,  2.8417e-02,  8.7302e-03, -6.4409e-03,\n",
       "                      -3.2618e-02, -1.0854e-02,  8.9898e-04, -2.9172e-02, -3.5870e-02,\n",
       "                       4.3228e-03,  1.7088e-02, -4.0346e-02, -2.9533e-02, -2.9019e-02,\n",
       "                       1.6307e-02, -1.2676e-02,  4.2133e-02,  6.3035e-03, -9.5179e-03,\n",
       "                      -1.4693e-02, -1.4821e-02,  2.5618e-02, -3.9299e-02, -1.9317e-02,\n",
       "                       3.2969e-02,  3.3600e-02,  3.9989e-02, -3.3297e-02,  2.0476e-02,\n",
       "                       1.7852e-02,  2.2399e-02,  2.4068e-02, -7.2349e-03,  3.9720e-02,\n",
       "                       1.7061e-02, -4.1427e-02,  2.6329e-02, -4.2471e-02, -4.0780e-02]))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(torch.rand(100, 100), \"tensor.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2520\n",
      "drwxrwxr-x 3 1000 1000    4096 Oct  9 12:07 .\n",
      "drwxrwxr-x 6 1000 1000    4096 Oct  8 15:15 ..\n",
      "drwxr-xr-x 2 root root    4096 Oct  8 13:52 .ipynb_checkpoints\n",
      "-rw-rw-r-- 1 1000 1000   93688 Oct  9 12:06 Seminar_2_Intro_to_DL.ipynb\n",
      "-rw-r--r-- 1 root root 2426420 Oct  9 12:03 model.pt\n",
      "-rw-r--r-- 1 root root   41111 Oct  9 12:07 tensor.pt\n"
     ]
    }
   ],
   "source": [
    "! ls -la"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1940, 0.7065, 0.8761,  ..., 0.6949, 0.0950, 0.5104],\n",
       "        [0.6817, 0.6439, 0.7966,  ..., 0.2392, 0.4570, 0.2767],\n",
       "        [0.1314, 0.3989, 0.3975,  ..., 0.6535, 0.0173, 0.4705],\n",
       "        ...,\n",
       "        [0.9745, 0.9852, 0.6879,  ..., 0.3329, 0.6604, 0.8833],\n",
       "        [0.6170, 0.9011, 0.5675,  ..., 0.0451, 0.3892, 0.8162],\n",
       "        [0.0395, 0.0873, 0.4839,  ..., 0.1275, 0.4015, 0.5961]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load(\"tensor.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Оптимизаторы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.optim.sgd.SGD, torch.optim.adam.Adam)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim.SGD, optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(net.parameters(), betas=(0.9, 0.999), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in parameters:\n",
    "    param = param - param.grad * self.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(\n",
    "    [\n",
    "        {'params': net.linear1.parameters()},\n",
    "        {'params': net.linear2.parameters(), 'lr': 1e-3}\n",
    "    ],\n",
    "    lr=1e-2,\n",
    "    momentum=0.9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGD (\n",
       "Parameter Group 0\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    lr: 0.01\n",
       "    maximize: False\n",
       "    momentum: 0.9\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    dampening: 0\n",
       "    differentiable: False\n",
       "    foreach: None\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    momentum: 0.9\n",
       "    nesterov: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer.zero_grad(set_to_none=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Функции потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.nn.modules.loss.L1Loss,\n",
       " torch.nn.modules.loss.MSELoss,\n",
       " torch.nn.modules.loss.CrossEntropyLoss,\n",
       " torch.nn.modules.loss.NLLLoss)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.L1Loss, nn.MSELoss, nn.CrossEntropyLoss, nn.NLLLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MSELoss()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.7448, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3, 5, requires_grad=True)\n",
    "target = torch.randn(3, 5)\n",
    "\n",
    "output = loss(x, target)\n",
    "\n",
    "print(output)\n",
    "\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1915, -0.3256, -0.3452,  0.4077, -0.0965],\n",
       "        [ 0.0080, -0.2400, -0.1864, -0.0920, -0.0071],\n",
       "        [-0.0399,  0.1643, -0.2740,  0.2657, -0.1392]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0833, -0.0875, -1.2107,  1.4702, -1.7268],\n",
       "         [-0.3889, -0.3152,  0.1784, -2.0484,  1.5957],\n",
       "         [-0.4154, -0.3775,  1.1265, -0.5106,  0.3695]], requires_grad=True),\n",
       " tensor([4, 0, 4]))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "x = torch.randn(3, 5, requires_grad=True)\n",
    "y = torch.empty(3, dtype=torch.long).random_(5)\n",
    "\n",
    "x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5241, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Датасеты и даталоадеры"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_features = 2\n",
    "n_objects = 300\n",
    "\n",
    "torch.manual_seed(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 1]), torch.Size([300, 2]), torch.Size([300, 1]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_true = torch.randn(n_features, 1)\n",
    "\n",
    "X = (torch.rand(n_objects, n_features) - 0.5) * 10\n",
    "X *= (torch.arange(n_features) * 2 + 1)\n",
    "\n",
    "Y = X @ w_true\n",
    "Y += torch.rand_like(Y)\n",
    "\n",
    "w_true.shape, X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5410],\n",
       "        [-0.2934]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.9258e+00,  4.0224e+00],\n",
       "        [-9.9066e-02,  1.1893e+01],\n",
       "        [-4.4372e-01,  3.9692e+00],\n",
       "        [-1.5111e+00, -2.9485e+00],\n",
       "        [-4.7767e+00, -9.9342e+00],\n",
       "        [-2.0611e+00,  5.5565e-01],\n",
       "        [ 1.9767e+00,  9.0003e+00],\n",
       "        [-3.3897e+00, -6.5319e+00],\n",
       "        [ 1.8161e+00,  1.2456e+01],\n",
       "        [-1.0290e+00,  1.1225e+01],\n",
       "        [-8.0592e-01,  1.5872e+00],\n",
       "        [ 4.5274e+00, -1.3915e+01],\n",
       "        [-3.1477e+00, -3.7975e+00],\n",
       "        [-1.9490e+00,  1.2960e+01],\n",
       "        [-3.2409e+00, -6.9050e+00],\n",
       "        [-3.4932e+00, -1.4048e+01],\n",
       "        [-2.9187e+00,  1.2894e+01],\n",
       "        [ 2.2311e+00,  7.2701e+00],\n",
       "        [ 2.6296e-01, -7.6903e+00],\n",
       "        [ 8.4592e-01, -1.4005e+01],\n",
       "        [-3.6128e+00, -7.7330e+00],\n",
       "        [ 3.1547e+00,  8.7948e+00],\n",
       "        [-2.2175e+00, -5.4124e-01],\n",
       "        [ 3.1978e+00,  1.4912e+01],\n",
       "        [ 1.9844e+00,  2.0264e+00],\n",
       "        [ 3.3524e+00, -8.8320e+00],\n",
       "        [ 9.3172e-01, -1.1630e+01],\n",
       "        [-3.4654e+00, -7.7488e+00],\n",
       "        [ 2.2624e+00,  6.0324e+00],\n",
       "        [-2.9618e+00,  4.5316e+00],\n",
       "        [ 2.7449e+00, -1.8933e+00],\n",
       "        [ 1.9091e-01,  3.4756e+00],\n",
       "        [ 3.1019e+00,  1.4403e+01],\n",
       "        [-3.8531e+00, -5.4970e+00],\n",
       "        [ 1.9650e+00,  1.2428e+01],\n",
       "        [ 4.3510e+00,  1.3235e+01],\n",
       "        [ 9.9507e-01, -1.3044e+01],\n",
       "        [ 4.5996e-01, -9.3841e+00],\n",
       "        [-4.6598e+00,  1.3327e+01],\n",
       "        [ 3.8018e+00, -1.4963e+01],\n",
       "        [ 9.3586e-01, -2.5269e+00],\n",
       "        [-8.2281e-01, -6.8664e+00],\n",
       "        [ 1.9228e+00, -8.8846e+00],\n",
       "        [ 1.8330e+00,  7.5856e+00],\n",
       "        [ 3.5794e+00,  5.6087e+00],\n",
       "        [-4.9487e+00, -9.7305e+00],\n",
       "        [ 2.4966e+00,  3.1395e+00],\n",
       "        [-3.9004e+00, -8.6373e+00],\n",
       "        [ 4.7037e+00,  1.0107e+01],\n",
       "        [-2.1801e+00, -3.7753e+00],\n",
       "        [-4.7630e+00, -2.6961e-01],\n",
       "        [-3.7653e+00, -1.1570e+01],\n",
       "        [-2.7550e-01,  2.2522e+00],\n",
       "        [-2.0477e+00,  8.9007e+00],\n",
       "        [-3.0427e+00,  1.3611e+01],\n",
       "        [ 3.4265e+00, -1.2649e+01],\n",
       "        [-1.2444e+00,  6.7684e-01],\n",
       "        [ 7.2951e-01,  3.5576e+00],\n",
       "        [ 1.9621e+00,  8.9850e-01],\n",
       "        [-2.4396e+00,  7.0978e+00],\n",
       "        [-4.7962e+00, -8.8906e+00],\n",
       "        [-1.2516e+00, -7.3067e+00],\n",
       "        [-1.7492e+00, -1.2294e+01],\n",
       "        [-1.0636e+00,  3.2063e+00],\n",
       "        [-3.2573e+00, -7.6979e-01],\n",
       "        [ 3.5793e+00, -1.5420e+00],\n",
       "        [ 1.3896e-01, -1.2940e+00],\n",
       "        [ 1.0119e+00,  9.5376e+00],\n",
       "        [ 4.7362e+00,  9.5258e+00],\n",
       "        [ 4.7471e+00, -1.0848e+00],\n",
       "        [-4.4916e+00, -7.1112e+00],\n",
       "        [ 3.4045e+00, -9.7237e-02],\n",
       "        [-2.4852e+00, -1.1495e+01],\n",
       "        [-4.6793e+00, -1.2660e+01],\n",
       "        [-1.0142e+00,  8.2261e+00],\n",
       "        [ 2.7032e+00, -1.4466e+01],\n",
       "        [ 3.1189e+00, -1.1738e+01],\n",
       "        [-1.0571e+00, -6.0821e+00],\n",
       "        [-9.6308e-01, -2.9451e+00],\n",
       "        [-4.4867e+00, -1.2952e+01],\n",
       "        [-7.8240e-01,  1.9398e-01],\n",
       "        [-2.2714e+00,  5.6505e+00],\n",
       "        [-4.5003e+00, -1.0123e+00],\n",
       "        [ 4.3971e+00, -6.1184e+00],\n",
       "        [ 4.5150e+00,  5.4323e+00],\n",
       "        [-4.5123e+00,  9.4905e+00],\n",
       "        [-5.7697e-01, -6.6961e+00],\n",
       "        [ 3.9983e+00, -1.2121e+01],\n",
       "        [ 5.3652e-01, -3.1405e+00],\n",
       "        [ 3.5706e+00,  4.1872e+00],\n",
       "        [ 2.4025e+00,  5.2974e+00],\n",
       "        [-1.2024e+00, -3.1546e+00],\n",
       "        [-4.1204e+00,  8.1277e+00],\n",
       "        [ 3.9699e+00,  1.0263e+01],\n",
       "        [-3.5269e+00,  6.6900e-01],\n",
       "        [-3.5247e+00, -8.2573e+00],\n",
       "        [-2.9135e+00,  5.1262e+00],\n",
       "        [-2.9796e+00, -3.2726e-01],\n",
       "        [ 2.1034e-01,  9.6693e+00],\n",
       "        [-3.7796e+00, -1.0298e+01],\n",
       "        [-2.9033e+00,  1.0499e+01],\n",
       "        [-1.7973e+00,  1.2652e+01],\n",
       "        [ 1.8080e+00,  1.8994e+00],\n",
       "        [-3.7220e-02, -2.9652e+00],\n",
       "        [ 6.2733e-01, -3.4252e+00],\n",
       "        [-3.5132e-02,  1.9139e+00],\n",
       "        [-3.9110e+00, -7.8620e+00],\n",
       "        [ 4.0375e+00, -1.2173e+01],\n",
       "        [-3.5903e-01,  1.4839e+01],\n",
       "        [ 1.8062e+00,  4.2470e-01],\n",
       "        [-4.3330e+00,  7.4307e+00],\n",
       "        [-3.5614e+00, -4.2580e+00],\n",
       "        [-1.6776e+00, -2.2213e+00],\n",
       "        [ 5.4691e-02,  1.2372e+01],\n",
       "        [ 6.2419e-01,  1.3435e+01],\n",
       "        [ 3.0586e+00, -9.4832e+00],\n",
       "        [ 2.2425e+00, -1.0603e+01],\n",
       "        [-2.1191e+00,  4.4118e+00],\n",
       "        [ 1.6510e+00,  1.1253e+01],\n",
       "        [-1.6096e+00,  2.4013e-02],\n",
       "        [ 2.5741e+00, -1.4506e+01],\n",
       "        [ 3.6149e+00, -1.2404e+01],\n",
       "        [ 6.8913e-02, -2.5503e+00],\n",
       "        [-2.6334e+00,  1.9826e+00],\n",
       "        [ 4.1346e+00, -4.3848e+00],\n",
       "        [-2.9685e+00, -5.5476e+00],\n",
       "        [-4.9557e+00,  6.7709e+00],\n",
       "        [-2.4013e+00, -1.0010e+01],\n",
       "        [-2.8805e+00,  8.6243e+00],\n",
       "        [ 2.6479e+00,  1.1513e+01],\n",
       "        [ 1.8136e+00, -5.0094e+00],\n",
       "        [-1.3972e+00,  4.4314e+00],\n",
       "        [ 4.1102e+00,  4.0784e+00],\n",
       "        [-2.3657e+00, -7.0512e+00],\n",
       "        [-4.7273e+00,  3.2407e+00],\n",
       "        [-2.8059e+00, -1.3374e+01],\n",
       "        [ 4.3844e+00, -9.7412e+00],\n",
       "        [-5.6881e-01,  4.2974e+00],\n",
       "        [ 1.5929e-01, -1.0093e+01],\n",
       "        [-4.0416e+00,  1.1956e+01],\n",
       "        [ 8.1419e-01,  1.2444e+01],\n",
       "        [-1.6762e+00,  4.4183e+00],\n",
       "        [-1.1434e+00, -6.6707e-01],\n",
       "        [-3.0452e+00,  5.0730e+00],\n",
       "        [ 1.5808e+00, -3.0943e-01],\n",
       "        [-1.1245e+00, -9.2464e+00],\n",
       "        [ 3.4577e+00, -1.1166e+01],\n",
       "        [ 2.0483e+00, -5.0438e+00],\n",
       "        [-2.4123e+00,  2.6947e+00],\n",
       "        [-2.5973e+00,  3.4561e+00],\n",
       "        [ 9.8190e-01, -1.1137e+01],\n",
       "        [ 8.3249e-01,  6.3889e+00],\n",
       "        [ 1.9792e+00, -1.8882e+00],\n",
       "        [-4.0989e+00, -2.3123e+00],\n",
       "        [ 1.7365e+00, -5.4732e+00],\n",
       "        [ 1.8979e+00,  9.9894e+00],\n",
       "        [-2.6108e+00,  1.4793e-01],\n",
       "        [ 2.0675e+00,  1.1757e+00],\n",
       "        [ 4.1766e-01,  1.8730e+00],\n",
       "        [-3.9307e+00,  1.1788e+00],\n",
       "        [ 3.4623e+00,  1.3517e+01],\n",
       "        [ 2.9388e+00,  2.0100e+00],\n",
       "        [ 2.3351e+00, -7.2972e+00],\n",
       "        [-4.1434e+00, -1.2899e+01],\n",
       "        [ 4.9880e+00,  9.5218e+00],\n",
       "        [-3.4562e+00,  5.8686e+00],\n",
       "        [ 3.7758e+00,  1.4994e+01],\n",
       "        [ 4.3720e+00,  1.1621e+01],\n",
       "        [-1.1463e+00, -5.2641e+00],\n",
       "        [ 4.1052e+00,  8.4057e+00],\n",
       "        [-3.0089e+00,  1.3485e+01],\n",
       "        [ 2.4158e+00,  8.1770e+00],\n",
       "        [-3.1339e+00,  4.3035e+00],\n",
       "        [-1.7528e+00,  1.1720e+01],\n",
       "        [-8.9970e-01,  5.8397e+00],\n",
       "        [ 8.8811e-01,  6.3820e+00],\n",
       "        [-1.6991e+00,  7.3136e+00],\n",
       "        [-3.4924e+00,  3.3878e+00],\n",
       "        [-3.3830e+00, -1.4798e+01],\n",
       "        [-4.0153e+00,  1.1842e+01],\n",
       "        [ 2.7052e+00,  1.4073e+01],\n",
       "        [ 4.0056e+00, -1.3396e+01],\n",
       "        [-3.4122e+00, -2.4237e+00],\n",
       "        [-3.2472e+00,  1.0416e+01],\n",
       "        [-3.7800e+00, -7.3185e+00],\n",
       "        [-4.8305e+00, -8.5162e+00],\n",
       "        [ 4.1124e+00,  1.2281e+01],\n",
       "        [ 3.5792e+00,  1.1582e+01],\n",
       "        [ 4.4459e+00, -3.8409e+00],\n",
       "        [ 2.2000e+00,  1.3364e+01],\n",
       "        [ 1.6541e+00,  1.4995e+01],\n",
       "        [ 2.5933e+00,  9.3247e+00],\n",
       "        [-1.7500e+00,  7.1974e+00],\n",
       "        [ 5.7453e-01, -3.5823e+00],\n",
       "        [-2.8185e+00, -8.4167e+00],\n",
       "        [-3.8474e+00,  1.0070e+01],\n",
       "        [ 3.5547e+00, -1.7072e+00],\n",
       "        [-2.8934e+00,  1.1594e+01],\n",
       "        [ 3.1974e+00,  1.1150e+00],\n",
       "        [-2.3607e+00,  1.3786e+01],\n",
       "        [ 2.0447e+00, -1.1387e+01],\n",
       "        [ 4.7854e+00,  1.1391e+01],\n",
       "        [-1.8225e+00,  8.4323e+00],\n",
       "        [-2.8409e+00, -2.3507e+00],\n",
       "        [ 4.2455e+00,  6.1979e-01],\n",
       "        [-3.5361e+00, -5.0135e+00],\n",
       "        [-1.3572e+00, -2.8939e+00],\n",
       "        [ 4.7850e-01,  1.3872e+01],\n",
       "        [ 2.6770e-01, -9.2616e+00],\n",
       "        [ 2.5627e-01,  7.1923e+00],\n",
       "        [ 2.4802e+00, -1.3709e+01],\n",
       "        [-8.9471e-01, -1.1147e+01],\n",
       "        [-2.1334e+00,  5.4044e+00],\n",
       "        [-3.5507e+00,  5.5759e+00],\n",
       "        [ 4.2439e+00,  9.8383e-01],\n",
       "        [-3.3324e+00, -5.3743e+00],\n",
       "        [ 1.0918e+00, -1.1435e+01],\n",
       "        [ 2.4841e+00, -1.3618e+01],\n",
       "        [-4.8065e+00, -1.4575e+01],\n",
       "        [-1.0143e+00,  1.0086e+01],\n",
       "        [-4.7324e+00,  1.2468e+01],\n",
       "        [-2.0001e+00,  4.3933e+00],\n",
       "        [ 2.2801e-01, -1.3526e+01],\n",
       "        [ 4.1466e+00,  8.0767e+00],\n",
       "        [ 4.9700e+00,  7.5782e+00],\n",
       "        [-3.3003e+00,  1.2519e+01],\n",
       "        [ 2.6872e-01,  7.1132e+00],\n",
       "        [-4.0091e+00, -4.3144e+00],\n",
       "        [-4.9094e+00, -5.8424e+00],\n",
       "        [ 1.0787e+00, -1.1777e+01],\n",
       "        [ 1.5938e+00,  8.0521e+00],\n",
       "        [ 6.9655e-01, -1.0036e+01],\n",
       "        [-3.8766e+00, -4.6277e+00],\n",
       "        [ 2.1948e+00,  1.4796e+01],\n",
       "        [ 2.8751e+00, -1.6891e+00],\n",
       "        [ 1.7531e+00, -1.4716e+01],\n",
       "        [-4.2705e+00,  6.9991e+00],\n",
       "        [-2.8321e+00,  7.2164e+00],\n",
       "        [-3.5297e+00, -7.4297e+00],\n",
       "        [-4.1184e+00,  7.8276e+00],\n",
       "        [-5.0948e-01,  1.1544e+01],\n",
       "        [ 3.0944e+00,  8.3001e+00],\n",
       "        [ 1.6078e-01, -4.6377e+00],\n",
       "        [-1.0872e+00,  1.9935e+00],\n",
       "        [ 2.4785e+00, -1.0509e+01],\n",
       "        [ 4.1964e+00, -1.6310e+00],\n",
       "        [-4.1897e+00, -8.1159e+00],\n",
       "        [ 4.4241e+00,  1.3718e+01],\n",
       "        [-4.6314e+00,  1.0579e+01],\n",
       "        [ 2.5058e+00,  8.8788e+00],\n",
       "        [ 4.2326e+00, -8.0843e+00],\n",
       "        [ 1.5789e+00,  6.1385e+00],\n",
       "        [-1.4775e+00,  5.0198e+00],\n",
       "        [-1.4386e+00,  9.2739e+00],\n",
       "        [-1.3873e+00, -5.5919e+00],\n",
       "        [ 1.2587e+00,  5.3204e+00],\n",
       "        [-2.4429e+00,  1.3260e+00],\n",
       "        [ 2.8977e+00, -1.4925e+00],\n",
       "        [ 1.5217e+00, -3.6178e+00],\n",
       "        [ 1.7525e+00, -1.0866e+01],\n",
       "        [-2.9401e+00, -7.6139e+00],\n",
       "        [ 4.5951e+00, -4.0363e+00],\n",
       "        [-1.3652e-02, -7.2674e+00],\n",
       "        [ 4.9915e+00,  1.4650e+01],\n",
       "        [-3.7709e+00, -1.2160e+01],\n",
       "        [-3.7900e+00, -7.2341e-02],\n",
       "        [-1.2745e+00, -9.8182e+00],\n",
       "        [-1.7934e+00,  2.8340e+00],\n",
       "        [-2.6125e+00,  3.3237e+00],\n",
       "        [-1.1466e+00, -7.2685e+00],\n",
       "        [ 6.8693e-01,  1.2334e+01],\n",
       "        [-3.3804e+00,  6.9652e-01],\n",
       "        [-1.8438e+00,  1.4720e+01],\n",
       "        [-4.7438e+00, -1.4380e+01],\n",
       "        [ 4.9269e+00, -9.4903e+00],\n",
       "        [ 9.5862e-01, -1.2946e+00],\n",
       "        [-1.0533e+00, -3.3502e+00],\n",
       "        [ 3.1772e+00,  7.1695e-01],\n",
       "        [-4.8681e+00, -8.8554e+00],\n",
       "        [-1.7045e+00,  7.5482e+00],\n",
       "        [-3.2357e+00,  1.4144e+01],\n",
       "        [-1.1136e+00, -2.6934e+00],\n",
       "        [ 3.9178e+00,  7.5391e+00],\n",
       "        [ 4.2406e+00,  8.6767e+00],\n",
       "        [-1.5168e+00, -9.9521e+00],\n",
       "        [-3.7202e-01,  1.2415e+01],\n",
       "        [-1.6781e+00, -1.3911e+01],\n",
       "        [ 2.0496e+00,  1.4602e+01],\n",
       "        [-1.4234e+00, -1.2420e+01],\n",
       "        [-4.5353e+00,  3.7590e+00],\n",
       "        [-3.7860e-01, -7.5748e+00],\n",
       "        [ 1.0107e+00,  5.6964e+00],\n",
       "        [ 3.9766e+00,  1.1646e+01],\n",
       "        [-7.4842e-01, -1.3227e+01],\n",
       "        [-4.5181e+00,  1.4005e+01],\n",
       "        [ 2.2103e+00,  6.5386e+00],\n",
       "        [-4.3261e+00,  1.3890e+01],\n",
       "        [ 4.7367e+00,  1.3543e+01],\n",
       "        [-4.2179e+00, -5.6599e+00],\n",
       "        [-3.4388e+00,  1.4204e+01]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -3.8627],\n",
       "        [ -3.3708],\n",
       "        [ -1.0865],\n",
       "        [ -1.1947],\n",
       "        [ -4.1922],\n",
       "        [ -2.8830],\n",
       "        [  0.8570],\n",
       "        [ -3.1964],\n",
       "        [  0.0605],\n",
       "        [ -4.5999],\n",
       "        [ -1.0303],\n",
       "        [ 11.9946],\n",
       "        [ -2.9841],\n",
       "        [ -6.2355],\n",
       "        [ -2.0427],\n",
       "        [ -0.6936],\n",
       "        [ -8.0125],\n",
       "        [  2.2778],\n",
       "        [  3.2801],\n",
       "        [  5.4253],\n",
       "        [ -2.9406],\n",
       "        [  2.4401],\n",
       "        [ -2.3199],\n",
       "        [  0.9696],\n",
       "        [  2.5076],\n",
       "        [  8.2262],\n",
       "        [  5.6622],\n",
       "        [ -2.4366],\n",
       "        [  2.3743],\n",
       "        [ -5.3473],\n",
       "        [  5.4718],\n",
       "        [ -0.3475],\n",
       "        [  0.8549],\n",
       "        [ -4.2920],\n",
       "        [ -0.4953],\n",
       "        [  3.5380],\n",
       "        [  5.5648],\n",
       "        [  4.0341],\n",
       "        [-10.4317],\n",
       "        [ 10.7845],\n",
       "        [  2.3594],\n",
       "        [  1.7250],\n",
       "        [  5.7792],\n",
       "        [  1.5100],\n",
       "        [  3.9723],\n",
       "        [ -4.3910],\n",
       "        [  3.6980],\n",
       "        [ -3.1804],\n",
       "        [  5.2027],\n",
       "        [ -2.0959],\n",
       "        [ -7.1805],\n",
       "        [ -2.1327],\n",
       "        [ -0.5046],\n",
       "        [ -4.8068],\n",
       "        [ -8.4212],\n",
       "        [  9.6707],\n",
       "        [ -1.7416],\n",
       "        [  0.4718],\n",
       "        [  3.6277],\n",
       "        [ -5.7297],\n",
       "        [ -4.2291],\n",
       "        [  1.1854],\n",
       "        [  1.3433],\n",
       "        [ -1.6916],\n",
       "        [ -4.4476],\n",
       "        [  6.8706],\n",
       "        [  0.6102],\n",
       "        [ -0.8113],\n",
       "        [  4.9155],\n",
       "        [  8.2956],\n",
       "        [ -4.1388],\n",
       "        [  6.1588],\n",
       "        [ -0.0314],\n",
       "        [ -3.0157],\n",
       "        [ -3.1342],\n",
       "        [  8.7752],\n",
       "        [  9.1887],\n",
       "        [  0.3228],\n",
       "        [ -0.1740],\n",
       "        [ -2.6406],\n",
       "        [ -0.5395],\n",
       "        [ -4.3164],\n",
       "        [ -6.2171],\n",
       "        [  8.6570],\n",
       "        [  6.1114],\n",
       "        [ -9.0887],\n",
       "        [  1.7766],\n",
       "        [  9.9097],\n",
       "        [  2.5701],\n",
       "        [  5.2472],\n",
       "        [  2.6913],\n",
       "        [ -0.8942],\n",
       "        [ -7.8834],\n",
       "        [  3.2353],\n",
       "        [ -5.0163],\n",
       "        [ -2.4359],\n",
       "        [ -5.7279],\n",
       "        [ -3.8214],\n",
       "        [ -2.4603],\n",
       "        [ -2.1888],\n",
       "        [ -7.3717],\n",
       "        [ -6.0363],\n",
       "        [  2.7932],\n",
       "        [  1.7387],\n",
       "        [  2.2332],\n",
       "        [  0.2046],\n",
       "        [ -3.2835],\n",
       "        [ 10.0562],\n",
       "        [ -4.8427],\n",
       "        [  2.6999],\n",
       "        [ -7.8693],\n",
       "        [ -3.8634],\n",
       "        [ -1.4084],\n",
       "        [ -2.9105],\n",
       "        [ -2.1406],\n",
       "        [  8.4226],\n",
       "        [  7.4726],\n",
       "        [ -4.4306],\n",
       "        [ -0.3381],\n",
       "        [ -2.2833],\n",
       "        [  8.4376],\n",
       "        [  9.8288],\n",
       "        [  1.8238],\n",
       "        [ -4.5403],\n",
       "        [  8.4606],\n",
       "        [ -2.7058],\n",
       "        [ -9.2209],\n",
       "        [  0.1337],\n",
       "        [ -6.5826],\n",
       "        [  1.2477],\n",
       "        [  4.4152],\n",
       "        [ -2.5278],\n",
       "        [  5.5724],\n",
       "        [ -1.4423],\n",
       "        [ -7.5893],\n",
       "        [ -0.2552],\n",
       "        [  9.7179],\n",
       "        [ -1.6071],\n",
       "        [  4.1035],\n",
       "        [ -9.3779],\n",
       "        [ -1.6615],\n",
       "        [ -2.9498],\n",
       "        [ -0.7346],\n",
       "        [ -5.9435],\n",
       "        [  2.9720],\n",
       "        [  1.3230],\n",
       "        [  8.7028],\n",
       "        [  5.1367],\n",
       "        [ -3.6319],\n",
       "        [ -4.0953],\n",
       "        [  5.3278],\n",
       "        [  0.0217],\n",
       "        [  3.8875],\n",
       "        [ -4.7605],\n",
       "        [  4.5739],\n",
       "        [  0.1461],\n",
       "        [ -3.4896],\n",
       "        [  3.6407],\n",
       "        [  0.1432],\n",
       "        [ -5.4512],\n",
       "        [  2.0491],\n",
       "        [  4.0885],\n",
       "        [  6.1318],\n",
       "        [ -1.6664],\n",
       "        [  5.0090],\n",
       "        [ -6.6941],\n",
       "        [  2.0828],\n",
       "        [  3.3891],\n",
       "        [  0.5523],\n",
       "        [  4.6200],\n",
       "        [ -7.7836],\n",
       "        [  1.5046],\n",
       "        [ -5.0941],\n",
       "        [ -5.9365],\n",
       "        [ -2.1008],\n",
       "        [ -0.4839],\n",
       "        [ -4.7099],\n",
       "        [ -5.5687],\n",
       "        [ -0.3187],\n",
       "        [ -9.1335],\n",
       "        [  0.2623],\n",
       "        [ 10.3936],\n",
       "        [ -4.1931],\n",
       "        [ -8.0473],\n",
       "        [ -3.1516],\n",
       "        [ -4.3564],\n",
       "        [  3.2330],\n",
       "        [  2.7785],\n",
       "        [  8.9526],\n",
       "        [  0.1018],\n",
       "        [ -1.5341],\n",
       "        [  1.5544],\n",
       "        [ -4.6285],\n",
       "        [  2.0899],\n",
       "        [ -1.4542],\n",
       "        [ -8.4721],\n",
       "        [  6.7011],\n",
       "        [ -7.5744],\n",
       "        [  5.4987],\n",
       "        [ -7.5338],\n",
       "        [  6.9936],\n",
       "        [  4.9814],\n",
       "        [ -4.2855],\n",
       "        [ -3.4777],\n",
       "        [  6.9495],\n",
       "        [ -3.4189],\n",
       "        [ -0.9767],\n",
       "        [ -3.0060],\n",
       "        [  3.7656],\n",
       "        [ -1.5632],\n",
       "        [  8.4271],\n",
       "        [  2.6085],\n",
       "        [ -4.5704],\n",
       "        [ -6.1924],\n",
       "        [  6.7182],\n",
       "        [ -2.8315],\n",
       "        [  6.0329],\n",
       "        [  8.1710],\n",
       "        [ -2.3583],\n",
       "        [ -4.1657],\n",
       "        [-10.5241],\n",
       "        [ -3.9560],\n",
       "        [  4.8171],\n",
       "        [  4.3312],\n",
       "        [  6.0523],\n",
       "        [ -8.2403],\n",
       "        [ -0.8562],\n",
       "        [ -4.5133],\n",
       "        [ -5.3009],\n",
       "        [  5.4320],\n",
       "        [  0.1746],\n",
       "        [  4.7206],\n",
       "        [ -4.0519],\n",
       "        [ -0.6596],\n",
       "        [  5.2572],\n",
       "        [  7.6503],\n",
       "        [ -8.2250],\n",
       "        [ -5.6550],\n",
       "        [ -2.7308],\n",
       "        [ -7.9545],\n",
       "        [ -3.4546],\n",
       "        [  2.7102],\n",
       "        [  2.3249],\n",
       "        [ -1.3913],\n",
       "        [  7.4260],\n",
       "        [  7.5430],\n",
       "        [ -3.5568],\n",
       "        [  3.6385],\n",
       "        [ -9.9524],\n",
       "        [  1.4903],\n",
       "        [  9.6125],\n",
       "        [  0.6967],\n",
       "        [ -3.2417],\n",
       "        [ -4.6680],\n",
       "        [  0.3331],\n",
       "        [  0.4130],\n",
       "        [ -3.3503],\n",
       "        [  5.8979],\n",
       "        [  4.0076],\n",
       "        [  6.3557],\n",
       "        [ -1.3044],\n",
       "        [  8.5516],\n",
       "        [  2.5714],\n",
       "        [  3.6741],\n",
       "        [ -1.8119],\n",
       "        [ -5.2104],\n",
       "        [  1.4837],\n",
       "        [ -3.1896],\n",
       "        [ -5.0010],\n",
       "        [  0.8915],\n",
       "        [ -2.0754],\n",
       "        [ -4.8383],\n",
       "        [ -6.2774],\n",
       "        [ -2.1047],\n",
       "        [ 10.5805],\n",
       "        [  2.3259],\n",
       "        [ -0.3404],\n",
       "        [  4.7249],\n",
       "        [ -4.7671],\n",
       "        [ -3.8722],\n",
       "        [ -8.3448],\n",
       "        [ -0.1572],\n",
       "        [  4.6030],\n",
       "        [  4.0915],\n",
       "        [  1.1354],\n",
       "        [ -3.2507],\n",
       "        [  1.7168],\n",
       "        [ -0.1814],\n",
       "        [  2.0824],\n",
       "        [ -7.2401],\n",
       "        [  1.9251],\n",
       "        [  0.6164],\n",
       "        [  2.7675],\n",
       "        [  3.1960],\n",
       "        [-10.4052],\n",
       "        [  2.1374],\n",
       "        [ -9.8239],\n",
       "        [  4.3167],\n",
       "        [ -3.8842],\n",
       "        [ -8.6315]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8515],\n",
       "        [0.4355]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = torch.rand_like(w_true)\n",
    "\n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([187, 129, 253, 265, 164,  94,  42, 234,  24,  46])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.5792, 11.5819],\n",
       "        [ 2.6479, 11.5128],\n",
       "        [-1.4386,  9.2739],\n",
       "        [-3.7900, -0.0723],\n",
       "        [ 4.9880,  9.5218],\n",
       "        [-3.5269,  0.6690],\n",
       "        [ 1.9228, -8.8846],\n",
       "        [ 2.8751, -1.6891],\n",
       "        [ 1.9844,  2.0264],\n",
       "        [ 2.4966,  3.1395]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = torch.randint(low=0, high=len(X), size=(10,))\n",
    "\n",
    "print(idx)\n",
    "\n",
    "X[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.3130],\n",
       "        [ 6.0207],\n",
       "        [ 7.4817],\n",
       "        [ 1.9516],\n",
       "        [ 3.3851],\n",
       "        [ 2.3044],\n",
       "        [-8.0110],\n",
       "        [-3.5445],\n",
       "        [ 0.0646],\n",
       "        [-0.2048]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[idx] @ w - Y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.3130],\n",
       "        [ 6.0207],\n",
       "        [ 7.4817],\n",
       "        [ 1.9516],\n",
       "        [ 3.3851],\n",
       "        [ 2.3044],\n",
       "        [-8.0110],\n",
       "        [-3.5445],\n",
       "        [ 0.0646],\n",
       "        [-0.2048]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X[idx] @ w - Y[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TensorDataset(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-3.3897, -6.5319]), tensor([-3.1964]))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([-3.3897, -6.5319]), tensor([-3.1964]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[7], Y[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# надо отнаследоваться от Dataset и определить методы __init__, __len__ и __getitem__\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, w_true, n_features, n_objects):\n",
    "        self.X = (torch.rand(n_objects, n_features) - 0.5) * 10\n",
    "        self.X *= (torch.arange(n_features) * 2 + 1)\n",
    "\n",
    "        self.Y = self.X @ w_true\n",
    "        self.Y += torch.rand_like(self.Y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.X[item], self.Y[item], \"123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset = CustomDataset(w_true, n_features, n_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.3076, 12.2098]), tensor([-2.5202]), 10)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3076, 12.2098])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.X[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=16, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x=tensor([[  2.8695, -13.2385],\n",
      "        [  0.4090, -12.7841],\n",
      "        [ -3.5551,   8.2670],\n",
      "        [  3.3531,   8.4646],\n",
      "        [ -0.4941,  -0.2621],\n",
      "        [  0.3434,   3.5632],\n",
      "        [ -3.4938,  -4.8072],\n",
      "        [  2.1194,   1.1347],\n",
      "        [ -1.0365,   3.9861],\n",
      "        [ -2.4309,  13.8347],\n",
      "        [  4.1109,   7.1128],\n",
      "        [  3.7930,  10.7865],\n",
      "        [  3.3728,   1.9850],\n",
      "        [  0.7799,  -2.0969],\n",
      "        [  0.1077,  -9.6033],\n",
      "        [  2.0626, -11.7493]])\tx.shape=torch.Size([16, 2])\n",
      "y=tensor([[ 8.4018],\n",
      "        [ 5.0162],\n",
      "        [-7.5136],\n",
      "        [ 3.2830],\n",
      "        [-0.6324],\n",
      "        [-0.2009],\n",
      "        [-3.8379],\n",
      "        [ 3.5353],\n",
      "        [-2.0856],\n",
      "        [-7.2310],\n",
      "        [ 5.0993],\n",
      "        [ 3.3871],\n",
      "        [ 5.2497],\n",
      "        [ 2.1592],\n",
      "        [ 3.7996],\n",
      "        [ 7.5756]])\ty.shape=torch.Size([16, 1])\n",
      "('123', '123', '123', '123', '123', '123', '123', '123', '123', '123', '123', '123', '123', '123', '123', '123')\n"
     ]
    }
   ],
   "source": [
    "for x, y, z in loader:\n",
    "    print(f\"{x=}\\t{x.shape=}\")\n",
    "    print(f\"{y=}\\t{y.shape=}\")\n",
    "    print(z)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Общая структура обучения модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "\n",
    "for x, y in dataloader:\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    output = model(x)\n",
    "\n",
    "    loss = loss_fn(output, y)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "def train(model: nn.Module, data_loader: DataLoader, optimizer: Optimizer, loss_fn):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, (x, y) in enumerate(tqdm(data_loader)):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "@torch.inference_mode()\n",
    "def evaluate(model: nn.Module, data_loader: DataLoader, loss_fn):\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, (x, y) in enumerate(tqdm(data_loader)):\n",
    "        output = model(x)\n",
    "\n",
    "        loss = loss_fn(output, y)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "sns.set(style='darkgrid')\n",
    "\n",
    "\n",
    "def plot_stats(\n",
    "    train_loss: list[float],\n",
    "    valid_loss: list[float],\n",
    "    title: str\n",
    "):\n",
    "    plt.figure(figsize=(16, 8))\n",
    "\n",
    "    plt.title(title + ' loss')\n",
    "\n",
    "    plt.plot(train_loss, label='Train loss')\n",
    "    plt.plot(valid_loss, label='Valid loss')\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def fit(model, train_loader, valid_loader, optimizer, loss_fn, num_epochs, title):\n",
    "    train_loss_history, valid_loss_history = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = train(model, train_loader, optimizer, loss_fn)\n",
    "        valid_loss = evaluate(model, valid_loader, loss_fn)\n",
    "\n",
    "        train_loss_history.append(train_loss)\n",
    "        valid_loss_history.append(valid_loss)\n",
    "\n",
    "        clear_output()\n",
    "\n",
    "        plot_stats(train_loss_history, valid_loss_history, title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Обучение первой нейросети в `PyTorch`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class CustomTaskNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.linear = nn.Linear(n_features, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "\n",
    "model = CustomTaskNetwork()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "\n",
    "dataset = TensorDataset(X, Y)\n",
    "\n",
    "train_dataset, valid_dataset = random_split(\n",
    "    dataset,\n",
    "    (int(len(dataset) * 0.8), len(dataset) -  int(len(dataset) * 0.8)),\n",
    "    generator=torch.Generator().manual_seed(300)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fit(model, train_loader, valid_loader, optimizer, loss_fn, 20, 'Simple fc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BatchNorm и Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dropout(p=0.1, inplace=False)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4857, 0.9035, 0.1018, 0.2132, 0.3809, 0.0729, 0.1050],\n",
       "        [0.8425, 0.5233, 0.0978, 0.4174, 0.4836, 0.3222, 0.0818],\n",
       "        [0.7721, 0.4382, 0.9882, 0.1171, 0.2255, 0.4740, 0.1518]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, 7)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5397, 1.0039, 0.1132, 0.2369, 0.4232, 0.0810, 0.1166],\n",
       "        [0.9361, 0.5815, 0.1086, 0.4638, 0.5373, 0.3580, 0.0909],\n",
       "        [0.8579, 0.4869, 1.0980, 0.1301, 0.2506, 0.5267, 0.1687]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x / 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5397, 1.0039, 0.1132, 0.2369, 0.4232, 0.0810, 0.1166],\n",
      "        [0.9361, 0.5815, 0.1086, 0.4638, 0.5373, 0.3580, 0.0909],\n",
      "        [0.8579, 0.4869, 1.0980, 0.1301, 0.2506, 0.5267, 0.1687]])\n",
      "tensor([[0.0000, 1.0039, 0.1132, 0.2369, 0.4232, 0.0810, 0.1166],\n",
      "        [0.9361, 0.5815, 0.1086, 0.4638, 0.5373, 0.3580, 0.0909],\n",
      "        [0.8579, 0.4869, 1.0980, 0.1301, 0.2506, 0.5267, 0.1687]])\n",
      "tensor([[0.5397, 1.0039, 0.1132, 0.0000, 0.4232, 0.0810, 0.1166],\n",
      "        [0.9361, 0.5815, 0.1086, 0.4638, 0.5373, 0.3580, 0.0909],\n",
      "        [0.8579, 0.4869, 1.0980, 0.1301, 0.0000, 0.5267, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "dropout.train()\n",
    "\n",
    "for _ in range(3):\n",
    "    print(dropout(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4857, 0.9035, 0.1018, 0.2132, 0.3809, 0.0729, 0.1050],\n",
       "        [0.8425, 0.5233, 0.0978, 0.4174, 0.4836, 0.3222, 0.0818],\n",
       "        [0.7721, 0.4382, 0.9882, 0.1171, 0.2255, 0.4740, 0.1518]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dropout.eval()\n",
    "\n",
    "dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm1d(7, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_norm = nn.BatchNorm1d(num_features=7)\n",
    "\n",
    "batch_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1844, 0.8558, 0.8472, 0.3011, 0.5549, 0.7383, 0.8578],\n",
       "        [0.0330, 0.9978, 0.3743, 0.7037, 0.1895, 0.1152, 0.1614],\n",
       "        [0.7947, 0.2534, 0.7907, 0.6512, 0.6989, 0.3888, 0.3418]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(3, 7)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4646,  0.4755,  0.8368, -1.4038,  0.3441,  1.2712,  1.3694],\n",
       "        [-0.9244,  0.9156, -1.4056,  0.8489, -1.3599, -1.1720, -0.9904],\n",
       "        [ 1.3890, -1.3911,  0.5688,  0.5548,  1.0157, -0.0992, -0.3789]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([1., 1., 1., 1., 1., 1., 1.], requires_grad=True)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_norm.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0., 0., 0., 0., 0., 0., 0.], requires_grad=True)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_norm.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_norm.running_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_norm.running_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_norm.num_batches_tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_norm(x)\n",
    "\n",
    "batch_norm.num_batches_tracked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1844, 0.8557, 0.8472, 0.3011, 0.5549, 0.7383, 0.8578],\n",
       "        [0.0330, 0.9978, 0.3743, 0.7037, 0.1895, 0.1152, 0.1614],\n",
       "        [0.7947, 0.2534, 0.7907, 0.6512, 0.6989, 0.3888, 0.3418]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_norm.eval()\n",
    "\n",
    "batch_norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1844, 0.8558, 0.8472, 0.3011, 0.5549, 0.7383, 0.8578],\n",
       "        [0.0330, 0.9978, 0.3743, 0.7037, 0.1895, 0.1152, 0.1614],\n",
       "        [0.7947, 0.2534, 0.7907, 0.6512, 0.6989, 0.3888, 0.3418]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm = nn.BatchNorm1d(num_features=7)\n",
    "\n",
    "batch_norm.eval()\n",
    "\n",
    "batch_norm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
